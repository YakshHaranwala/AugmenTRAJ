{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-08-23T00:44:05.285291945Z",
     "start_time": "2023-08-23T00:44:03.836573218Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from ptrail.core.TrajectoryDF import PTRAILDataFrame\n",
    "from ptrail.features.kinematic_features import KinematicFeatures\n",
    "\n",
    "from TestUtils.test_utils import TestUtils\n",
    "from src.selection.select import Selection\n",
    "from src.utils.general_utils import Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "data": {
      "text/plain": "                                   lat         lon  mode_of_transport  \\\ntraj_id DateTime                                                        \n10      2008-03-31 16:00:08  41.741415   86.186028                  1   \n        2008-03-31 16:01:07  41.737063   86.179470                  1   \n        2008-03-31 16:02:07  41.734105   86.172823                  1   \n        2008-03-31 16:03:06  41.739110   86.166563                  1   \n        2008-03-31 16:04:05  41.744368   86.159987                  1   \n...                                ...         ...                ...   \n98      2007-06-02 12:07:19  39.935300  116.468267                  1   \n        2007-06-02 12:07:58  39.935450  116.468333                  1   \n        2007-06-02 12:08:20  39.935400  116.468517                  1   \n        2007-06-02 12:09:40  39.934633  116.468983                  1   \n        2007-06-02 12:09:50  39.934717  116.468900                  1   \n\n                               Distance  \ntraj_id DateTime                         \n10      2008-03-31 16:00:08         NaN  \n        2008-03-31 16:01:07  728.185829  \n        2008-03-31 16:02:07  642.172796  \n        2008-03-31 16:03:06  761.267192  \n        2008-03-31 16:04:05  799.694199  \n...                                 ...  \n98      2007-06-02 12:07:19   14.666196  \n        2007-06-02 12:07:58   17.621166  \n        2007-06-02 12:08:20   16.590457  \n        2007-06-02 12:09:40   94.077625  \n        2007-06-02 12:09:50   11.676742  \n\n[355181 rows x 4 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th></th>\n      <th>lat</th>\n      <th>lon</th>\n      <th>mode_of_transport</th>\n      <th>Distance</th>\n    </tr>\n    <tr>\n      <th>traj_id</th>\n      <th>DateTime</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th rowspan=\"5\" valign=\"top\">10</th>\n      <th>2008-03-31 16:00:08</th>\n      <td>41.741415</td>\n      <td>86.186028</td>\n      <td>1</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2008-03-31 16:01:07</th>\n      <td>41.737063</td>\n      <td>86.179470</td>\n      <td>1</td>\n      <td>728.185829</td>\n    </tr>\n    <tr>\n      <th>2008-03-31 16:02:07</th>\n      <td>41.734105</td>\n      <td>86.172823</td>\n      <td>1</td>\n      <td>642.172796</td>\n    </tr>\n    <tr>\n      <th>2008-03-31 16:03:06</th>\n      <td>41.739110</td>\n      <td>86.166563</td>\n      <td>1</td>\n      <td>761.267192</td>\n    </tr>\n    <tr>\n      <th>2008-03-31 16:04:05</th>\n      <td>41.744368</td>\n      <td>86.159987</td>\n      <td>1</td>\n      <td>799.694199</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th rowspan=\"5\" valign=\"top\">98</th>\n      <th>2007-06-02 12:07:19</th>\n      <td>39.935300</td>\n      <td>116.468267</td>\n      <td>1</td>\n      <td>14.666196</td>\n    </tr>\n    <tr>\n      <th>2007-06-02 12:07:58</th>\n      <td>39.935450</td>\n      <td>116.468333</td>\n      <td>1</td>\n      <td>17.621166</td>\n    </tr>\n    <tr>\n      <th>2007-06-02 12:08:20</th>\n      <td>39.935400</td>\n      <td>116.468517</td>\n      <td>1</td>\n      <td>16.590457</td>\n    </tr>\n    <tr>\n      <th>2007-06-02 12:09:40</th>\n      <td>39.934633</td>\n      <td>116.468983</td>\n      <td>1</td>\n      <td>94.077625</td>\n    </tr>\n    <tr>\n      <th>2007-06-02 12:09:50</th>\n      <td>39.934717</td>\n      <td>116.468900</td>\n      <td>1</td>\n      <td>11.676742</td>\n    </tr>\n  </tbody>\n</table>\n<p>355181 rows Ã— 4 columns</p>\n</div>"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gl_dataset = PTRAILDataFrame(data_set=pd.read_csv('../TestUtils/geolife.csv'),\n",
    "                             traj_id='traj_id',\n",
    "                             datetime='DateTime',\n",
    "                             latitude='lat',\n",
    "                             longitude='lon')\n",
    "ready_dataset = KinematicFeatures.create_distance_column(gl_dataset)\n",
    "ready_dataset"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-23T00:44:06.019830543Z",
     "start_time": "2023-08-23T00:44:05.288698757Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "def find_original_and_augmentation_pairs_and_calculate_differences(augmented_dataset, selected):\n",
    "    # Find augmented trajectories associated with each original trajectory.\n",
    "    select_to_augment_map = {}\n",
    "    for traj_id in selected:\n",
    "        pattern = r'\\b{}aug'.format(traj_id)\n",
    "        conditions = augmented_dataset.index.str.match(pattern)\n",
    "        select_to_augment_map[traj_id] = augmented_dataset.loc[conditions].index.unique()\n",
    "\n",
    "    # Now, for each original trajectory, calculate the features for all of them\n",
    "    # and then find the vector difference between the vectors.\n",
    "    distances = []\n",
    "    for traj_id in selected:\n",
    "        # Get the features of the original traj.\n",
    "        original_features = augmented_dataset.loc[augmented_dataset.index == traj_id].to_numpy()\n",
    "\n",
    "        # Get the features of the augmented trajectories.\n",
    "        aug_features = augmented_dataset.loc[augmented_dataset.index.isin(select_to_augment_map[traj_id])].to_numpy()\n",
    "\n",
    "        # # Now, for each augmented trajectory, find the euclidean distance between the\n",
    "        # # features of original trajectory and augmented trajectory and store it in a list.\n",
    "        for aug in aug_features:\n",
    "            distance = np.linalg.norm(original_features - aug)\n",
    "            distances.append(distance)\n",
    "\n",
    "    return round(np.mean(distances), 4), round(np.std(distances), 4)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-23T00:44:06.025567179Z",
     "start_time": "2023-08-23T00:44:06.023419123Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[143316.3892, 456544.8241, 11538.2794, 14933.5641, 206350.7905, 553257.9977, 15409.2766, 19831.7347, 252410.7804, 619242.8758, 17880.7165, 23253.8537]\n",
      "[94512.5877, 351465.3907, 12041.3629, 14876.9007, 162365.7311, 482820.579, 15488.1128, 19597.8435, 217548.299, 571151.1602, 17653.6619, 22899.5168]\n",
      "[2265942.884, 5553803.6525, 1278464.5098, 3307891.6782, 3364793.2594, 7933765.7876, 1292738.4402, 3316185.2571, 4129130.87, 8950248.3972, 1317532.3597, 3355097.8551]\n",
      "[559438.2436, 1789049.0008, 47280.8841, 104768.9898, 756000.8472, 2065040.8546, 50289.4779, 108062.9226, 887267.4177, 2297022.7388, 51915.451, 109927.8114]\n",
      "[2527216.7915, 6201294.0929, 1329281.8663, 3426244.1995, 3908630.3395, 8856485.226, 1342898.6603, 3430839.9564, 4548961.9902, 9913318.4527, 1358234.3029, 3443772.7947]\n",
      "[1100210.0418, 2486908.7723, 133379.3116, 263326.3914, 1740134.8121, 3141281.9341, 168316.2872, 272616.3637, 1907402.0105, 3227228.9325, 179410.3818, 280223.1423]\n",
      "[1005519.1697, 2291353.7582, 61136.999, 103126.9093, 1737725.938, 2880320.0962, 91258.1965, 126811.4178, 1925879.6048, 2982766.2817, 95561.7725, 129831.8188]\n",
      "[634208.1989, 1706469.6772, 54486.2833, 104090.3735, 888752.0225, 2014663.7077, 83388.647, 128421.9806, 1020091.5009, 2132000.8781, 86423.3455, 131720.498]\n",
      "[876513.478, 2640084.0464, 112366.5813, 267603.8125, 1071393.6889, 2946554.8864, 118044.9298, 275205.764, 1213771.1881, 3165295.2889, 122720.843, 283598.7002]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[4], line 17\u001B[0m\n\u001B[1;32m     13\u001B[0m train, test_x, test_y \u001B[38;5;241m=\u001B[39m TestUtils\u001B[38;5;241m.\u001B[39mget_test_train_data(dataset\u001B[38;5;241m=\u001B[39mready_dataset, seed_val\u001B[38;5;241m=\u001B[39mseed,\n\u001B[1;32m     14\u001B[0m                                                       class_col\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mmode_of_transport\u001B[39m\u001B[38;5;124m'\u001B[39m, k\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0.8\u001B[39m)\n\u001B[1;32m     16\u001B[0m selected \u001B[38;5;241m=\u001B[39m Selection\u001B[38;5;241m.\u001B[39mselect_randomly(train, seed, k\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0.3\u001B[39m)\n\u001B[0;32m---> 17\u001B[0m train_x, train_y \u001B[38;5;241m=\u001B[39m \u001B[43mTestUtils\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43maugment_trajectories_using_random_strategy\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdataset\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtrain\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     18\u001B[0m \u001B[43m                                                                        \u001B[49m\u001B[43mpercent_to_shake\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mshake\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     19\u001B[0m \u001B[43m                                                                        \u001B[49m\u001B[43mids_to_augment\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mselected\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     20\u001B[0m \u001B[43m                                                                        \u001B[49m\u001B[43mcircle\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmethod\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     21\u001B[0m \u001B[43m                                                                        \u001B[49m\u001B[43mn_augmentations\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m20\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m     22\u001B[0m \u001B[43m                                                                        \u001B[49m\u001B[43mclass_col\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mmode_of_transport\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m     23\u001B[0m mean, std \u001B[38;5;241m=\u001B[39m find_original_and_augmentation_pairs_and_calculate_differences(train_x, selected)\n\u001B[1;32m     24\u001B[0m row\u001B[38;5;241m.\u001B[39mappend(mean)\n",
      "File \u001B[0;32m~/Desktop/AugmenTRAJ/test/TestUtils/test_utils.py:230\u001B[0m, in \u001B[0;36mTestUtils.augment_trajectories_using_random_strategy\u001B[0;34m(dataset, ids_to_augment, circle, class_col, n_augmentations, percent_to_shake)\u001B[0m\n\u001B[1;32m    228\u001B[0m \u001B[38;5;66;03m# subsequent augmentations.\u001B[39;00m\n\u001B[1;32m    229\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m i \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(\u001B[38;5;241m1\u001B[39m, n_augmentations):\n\u001B[0;32m--> 230\u001B[0m     dataset \u001B[38;5;241m=\u001B[39m \u001B[43mAugmentation\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43maugment_trajectories_with_randomly_generated_points\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdataset\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    231\u001B[0m \u001B[43m                                                                               \u001B[49m\u001B[43mids_to_augment\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mids_to_augment\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    232\u001B[0m \u001B[43m                                                                               \u001B[49m\u001B[43mcircle\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcircle\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    233\u001B[0m \u001B[43m                                                                               \u001B[49m\u001B[43mpercent_to_shake\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mpercent_to_shake\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    235\u001B[0m \u001B[38;5;66;03m# convert to segment based format and return.\u001B[39;00m\n\u001B[1;32m    236\u001B[0m pivoted \u001B[38;5;241m=\u001B[39m Statistics\u001B[38;5;241m.\u001B[39mpivot_stats_df(\n\u001B[1;32m    237\u001B[0m     dataframe\u001B[38;5;241m=\u001B[39mStatistics\u001B[38;5;241m.\u001B[39mgenerate_kinematic_stats(dataset, class_col), target_col_name\u001B[38;5;241m=\u001B[39mclass_col)\u001B[38;5;241m.\u001B[39mdropna()\n",
      "File \u001B[0;32m~/Desktop/AugmenTRAJ/src/augmentation/augment.py:63\u001B[0m, in \u001B[0;36mAugmentation.augment_trajectories_with_randomly_generated_points\u001B[0;34m(dataset, percent_to_shake, ids_to_augment, circle)\u001B[0m\n\u001B[1;32m     61\u001B[0m row \u001B[38;5;241m=\u001B[39m small\u001B[38;5;241m.\u001B[39mloc[points_to_change[i]]\n\u001B[1;32m     62\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m circle \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mon\u001B[39m\u001B[38;5;124m'\u001B[39m:\n\u001B[0;32m---> 63\u001B[0m     \u001B[43msmall\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mloc\u001B[49m\u001B[43m[\u001B[49m\u001B[43mi\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mlat\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m \u001B[38;5;241m=\u001B[39m Alter\u001B[38;5;241m.\u001B[39malter_point_on_circle(row, angle, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mlatitude\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[1;32m     64\u001B[0m     small\u001B[38;5;241m.\u001B[39mloc[i, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mlon\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;241m=\u001B[39m Alter\u001B[38;5;241m.\u001B[39malter_point_on_circle(row, angle, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mlongitude\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[1;32m     65\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m circle \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124min\u001B[39m\u001B[38;5;124m'\u001B[39m:\n",
      "File \u001B[0;32m~/anaconda3/envs/PreprocessingLibrary/lib/python3.8/site-packages/pandas/core/indexing.py:818\u001B[0m, in \u001B[0;36m_LocationIndexer.__setitem__\u001B[0;34m(self, key, value)\u001B[0m\n\u001B[1;32m    815\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_has_valid_setitem_indexer(key)\n\u001B[1;32m    817\u001B[0m iloc \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mname \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124miloc\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mobj\u001B[38;5;241m.\u001B[39miloc\n\u001B[0;32m--> 818\u001B[0m \u001B[43miloc\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_setitem_with_indexer\u001B[49m\u001B[43m(\u001B[49m\u001B[43mindexer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mvalue\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mname\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/anaconda3/envs/PreprocessingLibrary/lib/python3.8/site-packages/pandas/core/indexing.py:1774\u001B[0m, in \u001B[0;36m_iLocIndexer._setitem_with_indexer\u001B[0;34m(self, indexer, value, name)\u001B[0m\n\u001B[1;32m   1771\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mobj\u001B[38;5;241m.\u001B[39m_maybe_update_cacher(clear\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[1;32m   1772\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mobj\u001B[38;5;241m.\u001B[39m_is_copy \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m-> 1774\u001B[0m     nindexer\u001B[38;5;241m.\u001B[39mappend(\u001B[43mlabels\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_loc\u001B[49m\u001B[43m(\u001B[49m\u001B[43mkey\u001B[49m\u001B[43m)\u001B[49m)\n\u001B[1;32m   1776\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m   1777\u001B[0m     nindexer\u001B[38;5;241m.\u001B[39mappend(idx)\n",
      "File \u001B[0;32m~/anaconda3/envs/PreprocessingLibrary/lib/python3.8/site-packages/pandas/core/indexes/base.py:3802\u001B[0m, in \u001B[0;36mIndex.get_loc\u001B[0;34m(self, key, method, tolerance)\u001B[0m\n\u001B[1;32m   3800\u001B[0m casted_key \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_maybe_cast_indexer(key)\n\u001B[1;32m   3801\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m-> 3802\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_engine\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_loc\u001B[49m\u001B[43m(\u001B[49m\u001B[43mcasted_key\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   3803\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mKeyError\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m err:\n\u001B[1;32m   3804\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mKeyError\u001B[39;00m(key) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01merr\u001B[39;00m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "seed_generator = Utilities.generate_pi_seed(20)\n",
    "seed_vals = [next(seed_generator) for i in range(20)]\n",
    "shake_percentages = [0.2, 0.4, 0.6]\n",
    "circle_methods = ['on', 'in']\n",
    "\n",
    "results = [\"on_20%_dist,on_20%_std,on_40%_std,on_40%_std,on_60%_std,on_60%_std,\"\n",
    "           \"in_20%_dist,in_20%_std,in_40%_std,in_40%_std,in_60%_std,in_60%_std\"]\n",
    "\n",
    "for seed in seed_vals:\n",
    "    row = []\n",
    "    for shake in shake_percentages:\n",
    "        for method in circle_methods:\n",
    "            train, test_x, test_y = TestUtils.get_test_train_data(dataset=ready_dataset, seed_val=seed,\n",
    "                                                                  class_col='mode_of_transport', k=0.8)\n",
    "\n",
    "            selected = Selection.select_randomly(train, seed, k=0.3)\n",
    "            train_x, train_y = TestUtils.augment_trajectories_using_random_strategy(dataset=train,\n",
    "                                                                                    percent_to_shake=shake,\n",
    "                                                                                    ids_to_augment=selected,\n",
    "                                                                                    circle=method,\n",
    "                                                                                    n_augmentations=20,\n",
    "                                                                                    class_col=\"mode_of_transport\")\n",
    "            mean, std = find_original_and_augmentation_pairs_and_calculate_differences(train_x, selected)\n",
    "            row.append(mean)\n",
    "            row.append(std)\n",
    "    print(row)\n",
    "    results.append(row)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-23T14:07:22.540860995Z",
     "start_time": "2023-08-23T00:44:06.028703493Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "results[0] = [\"on_20%_dist\", \"on_20%_std\", \"on_40%_dist\", \"on_40%_std\", \"on_60%_dist\", \"on_60%_std\",\n",
    "              \"in_20%_dist\",\"in_20%_std\",\"in_40%_dist\",\"in_40%_std\",\"in_60%_dist\",\"in_60%_std\"]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-08-23T14:07:22.540716431Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "with open(\"../results/experiment_1/geolife.csv\", \"w\") as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerows(results)"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
