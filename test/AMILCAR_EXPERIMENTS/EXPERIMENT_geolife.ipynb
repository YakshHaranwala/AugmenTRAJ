{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-08-24T20:56:07.984174073Z",
     "start_time": "2023-08-24T20:56:05.632932306Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from ptrail.core.TrajectoryDF import PTRAILDataFrame\n",
    "from ptrail.features.kinematic_features import KinematicFeatures\n",
    "from ptrail.core.Datasets import Datasets\n",
    "from ptrail.preprocessing.statistics import Statistics\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier, GradientBoostingClassifier\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from src.utils.test_utils import TestUtils\n",
    "from src.selection.select import Selection\n",
    "from src.utils.general_utils import Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "data": {
      "text/plain": "                                   lat         lon  mode_of_transport  \\\ntraj_id DateTime                                                        \n10      2008-03-31 16:00:08  41.741415   86.186028                  1   \n        2008-03-31 16:01:07  41.737063   86.179470                  1   \n        2008-03-31 16:02:07  41.734105   86.172823                  1   \n        2008-03-31 16:03:06  41.739110   86.166563                  1   \n        2008-03-31 16:04:05  41.744368   86.159987                  1   \n...                                ...         ...                ...   \n98      2007-06-02 12:07:19  39.935300  116.468267                  1   \n        2007-06-02 12:07:58  39.935450  116.468333                  1   \n        2007-06-02 12:08:20  39.935400  116.468517                  1   \n        2007-06-02 12:09:40  39.934633  116.468983                  1   \n        2007-06-02 12:09:50  39.934717  116.468900                  1   \n\n                               Distance  \ntraj_id DateTime                         \n10      2008-03-31 16:00:08         NaN  \n        2008-03-31 16:01:07  728.185829  \n        2008-03-31 16:02:07  642.172796  \n        2008-03-31 16:03:06  761.267192  \n        2008-03-31 16:04:05  799.694199  \n...                                 ...  \n98      2007-06-02 12:07:19   14.666196  \n        2007-06-02 12:07:58   17.621166  \n        2007-06-02 12:08:20   16.590457  \n        2007-06-02 12:09:40   94.077625  \n        2007-06-02 12:09:50   11.676742  \n\n[355181 rows x 4 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th></th>\n      <th>lat</th>\n      <th>lon</th>\n      <th>mode_of_transport</th>\n      <th>Distance</th>\n    </tr>\n    <tr>\n      <th>traj_id</th>\n      <th>DateTime</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th rowspan=\"5\" valign=\"top\">10</th>\n      <th>2008-03-31 16:00:08</th>\n      <td>41.741415</td>\n      <td>86.186028</td>\n      <td>1</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2008-03-31 16:01:07</th>\n      <td>41.737063</td>\n      <td>86.179470</td>\n      <td>1</td>\n      <td>728.185829</td>\n    </tr>\n    <tr>\n      <th>2008-03-31 16:02:07</th>\n      <td>41.734105</td>\n      <td>86.172823</td>\n      <td>1</td>\n      <td>642.172796</td>\n    </tr>\n    <tr>\n      <th>2008-03-31 16:03:06</th>\n      <td>41.739110</td>\n      <td>86.166563</td>\n      <td>1</td>\n      <td>761.267192</td>\n    </tr>\n    <tr>\n      <th>2008-03-31 16:04:05</th>\n      <td>41.744368</td>\n      <td>86.159987</td>\n      <td>1</td>\n      <td>799.694199</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th rowspan=\"5\" valign=\"top\">98</th>\n      <th>2007-06-02 12:07:19</th>\n      <td>39.935300</td>\n      <td>116.468267</td>\n      <td>1</td>\n      <td>14.666196</td>\n    </tr>\n    <tr>\n      <th>2007-06-02 12:07:58</th>\n      <td>39.935450</td>\n      <td>116.468333</td>\n      <td>1</td>\n      <td>17.621166</td>\n    </tr>\n    <tr>\n      <th>2007-06-02 12:08:20</th>\n      <td>39.935400</td>\n      <td>116.468517</td>\n      <td>1</td>\n      <td>16.590457</td>\n    </tr>\n    <tr>\n      <th>2007-06-02 12:09:40</th>\n      <td>39.934633</td>\n      <td>116.468983</td>\n      <td>1</td>\n      <td>94.077625</td>\n    </tr>\n    <tr>\n      <th>2007-06-02 12:09:50</th>\n      <td>39.934717</td>\n      <td>116.468900</td>\n      <td>1</td>\n      <td>11.676742</td>\n    </tr>\n  </tbody>\n</table>\n<p>355181 rows Ã— 4 columns</p>\n</div>"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gl_dataset = PTRAILDataFrame(data_set=pd.read_csv('../TestUtils/geolife.csv'),\n",
    "                             traj_id='traj_id',\n",
    "                             datetime='DateTime',\n",
    "                             latitude='lat',\n",
    "                             longitude='lon')\n",
    "ready_dataset = KinematicFeatures.create_distance_column(gl_dataset)\n",
    "ready_dataset"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-24T20:56:09.220642873Z",
     "start_time": "2023-08-24T20:56:07.980132257Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1415, 'ExtraTreesClassifier', 0.5, 0.6429, 0.6429, 0.6429, 0.6429, 0.6429, 0.7667], [1415, 'GradientBoostingClassifier', 0.6455, 0.5333, 0.5333, 0.5333, 0.5333, 0.5333, 0.5333], [1415, 'RandomForestClassifier', 0.7667, 0.7667, 0.6429, 0.7667, 0.7667, 0.7667, 0.7667]]\n",
      "[[9265, 'ExtraTreesClassifier', 0.6864, 0.6864, 0.6864, 0.6864, 0.6864, 0.6864, 0.6864], [9265, 'GradientBoostingClassifier', 0.6864, 0.5667, 0.5667, 0.5667, 0.6864, 0.6864, 0.6864], [9265, 'RandomForestClassifier', 0.6864, 0.6731, 0.6731, 0.6731, 0.6731, 0.6731, 0.6731]]\n",
      "[[3589, 'ExtraTreesClassifier', 0.5, 0.5, 0.3452, 0.5, 0.5, 0.3452, 0.0833], [3589, 'GradientBoostingClassifier', 0.3849, 0.631, 0.631, 0.631, 0.75, 0.15, 0.15], [3589, 'RandomForestClassifier', 0.5, 0.631, 0.5, 0.5, 0.631, 0.631, 0.5]]\n",
      "[[7932, 'ExtraTreesClassifier', 0.6455, 0.6429, 0.7667, 0.6429, 0.5, 0.6429, 0.5], [7932, 'GradientBoostingClassifier', 0.6455, 0.7667, 0.7667, 0.7667, 0.7667, 0.6455, 0.6455], [7932, 'RandomForestClassifier', 0.7667, 0.7667, 0.7667, 0.7667, 0.7667, 0.5, 0.5]]\n",
      "[[3846, 'ExtraTreesClassifier', 0.4167, 0.6045, 0.6045, 0.6045, 0.6045, 0.7083, 0.6045], [3846, 'GradientBoostingClassifier', 0.6045, 0.6045, 0.6045, 0.5, 0.5, 0.4808, 0.4808], [3846, 'RandomForestClassifier', 0.6045, 0.6045, 0.6045, 0.6045, 0.75, 0.7083, 0.7083]]\n",
      "[[2643, 'ExtraTreesClassifier', 0.5636, 0.7333, 0.7333, 0.7333, 0.7333, 0.7333, 0.7333], [2643, 'GradientBoostingClassifier', 0.7333, 0.7333, 0.7333, 0.75, 0.75, 0.75, 0.75], [2643, 'RandomForestClassifier', 0.5636, 0.5636, 0.2727, 0.7333, 0.75, 0.873, 0.7333]]\n",
      "[[3832, 'ExtraTreesClassifier', 0.6455, 0.5333, 0.6455, 0.6455, 0.6455, 0.75, 0.75], [3832, 'GradientBoostingClassifier', 0.75, 0.5769, 0.5769, 0.5769, 0.5769, 0.5769, 0.8818], [3832, 'RandomForestClassifier', 0.5769, 0.6455, 0.6455, 0.6429, 0.6455, 0.7667, 0.6455]]\n",
      "[[7950, 'ExtraTreesClassifier', 0.631, 0.5, 0.3452, 0.5, 0.5, 0.3452, 0.3452], [7950, 'GradientBoostingClassifier', 0.3452, 0.4333, 0.2045, 0.4333, 0.4333, 0.4333, 0.2045], [7950, 'RandomForestClassifier', 0.25, 0.15, 0.3452, 0.15, 0.15, 0.2045, 0.3452]]\n",
      "[[2884, 'ExtraTreesClassifier', 0.619, 0.619, 0.619, 0.619, 0.75, 0.619, 0.75], [2884, 'GradientBoostingClassifier', 0.75, 0.75, 0.75, 0.75, 0.75, 0.75, 0.75], [2884, 'RandomForestClassifier', 0.75, 0.75, 0.75, 0.75, 0.75, 0.75, 0.619]]\n",
      "[[1971, 'ExtraTreesClassifier', 0.5, 0.4333, 0.4333, 0.6071, 0.6071, 0.6071, 0.6071], [1971, 'GradientBoostingClassifier', 0.7083, 0.7083, 0.7083, 0.4167, 0.4167, 0.4167, 0.4167], [1971, 'RandomForestClassifier', 0.5, 0.5, 0.5, 0.75, 0.631, 0.4808, 0.5]]\n",
      "[[6939, 'ExtraTreesClassifier', 0.75, 0.75, 0.75, 0.75, 0.75, 0.75, 0.8682], [6939, 'GradientBoostingClassifier', 0.75, 0.75, 0.75, 0.75, 0.75, 0.75, 0.75], [6939, 'RandomForestClassifier', 0.8682, 0.75, 0.8682, 0.8682, 0.8682, 0.8682, 0.8682]]\n",
      "[[9375, 'ExtraTreesClassifier', 0.5667, 0.5667, 0.25, 0.4246, 0.4246, 0.5667, 0.4246], [9375, 'GradientBoostingClassifier', 0.1944, 0.6864, 0.6864, 0.6864, 0.6864, 0.6864, 0.6864], [9375, 'RandomForestClassifier', 0.7917, 0.5667, 0.6864, 0.6864, 0.6864, 0.6864, 0.6864]]\n",
      "[[1058, 'ExtraTreesClassifier', 0.7083, 0.8682, 0.7083, 0.8682, 0.7083, 0.8682, 0.8682], [1058, 'GradientBoostingClassifier', 0.6045, 1.0, 1.0, 0.75, 0.75, 0.75, 0.75], [1058, 'RandomForestClassifier', 0.8682, 0.7083, 0.8682, 0.7083, 0.7083, 0.8682, 0.8682]]\n",
      "[[2097, 'ExtraTreesClassifier', 0.631, 0.6071, 0.4333, 0.6071, 0.6071, 0.6071, 0.5], [2097, 'GradientBoostingClassifier', 0.6045, 1.0, 1.0, 1.0, 0.877, 1.0, 0.75], [2097, 'RandomForestClassifier', 0.25, 0.631, 0.25, 0.631, 0.3849, 0.7083, 0.5]]\n",
      "[[4944, 'ExtraTreesClassifier', 0.7333, 0.619, 0.619, 0.619, 0.75, 0.619, 0.75], [4944, 'GradientBoostingClassifier', 0.5636, 0.3333, 0.3333, 0.3333, 0.3333, 0.3333, 0.3333], [4944, 'RandomForestClassifier', 0.873, 0.873, 0.7333, 0.5636, 0.75, 0.5636, 0.75]]\n",
      "[[5923, 'ExtraTreesClassifier', 0.619, 0.7333, 0.5636, 0.7333, 0.7333, 0.7333, 0.7333], [5923, 'GradientBoostingClassifier', 0.7333, 0.5636, 0.3333, 0.5636, 0.3333, 0.5636, 0.3333], [5923, 'RandomForestClassifier', 0.873, 0.873, 0.873, 0.873, 0.873, 0.5636, 0.5636]]\n",
      "[[781, 'ExtraTreesClassifier', 0.75, 0.75, 0.75, 0.6071, 0.6071, 0.6071, 0.6071], [781, 'GradientBoostingClassifier', 0.6071, 0.75, 0.877, 0.75, 0.75, 0.75, 0.75], [781, 'RandomForestClassifier', 0.6071, 0.75, 0.75, 0.75, 0.75, 0.75, 0.75]]\n",
      "[[6406, 'ExtraTreesClassifier', 0.859, 0.75, 0.75, 0.6455, 0.6455, 0.75, 0.75], [6406, 'GradientBoostingClassifier', 0.6429, 0.4091, 0.5333, 0.4091, 0.5333, 0.4091, 0.5333], [6406, 'RandomForestClassifier', 0.859, 1.0, 0.859, 0.859, 0.859, 0.859, 0.859]]\n",
      "[[2862, 'ExtraTreesClassifier', 0.7917, 0.5667, 0.5667, 0.6864, 0.5667, 0.6864, 0.6864], [2862, 'GradientBoostingClassifier', 0.7917, 0.75, 0.75, 0.891, 0.891, 0.7917, 0.7917], [2862, 'RandomForestClassifier', 0.7917, 0.6864, 0.6864, 0.6864, 0.6864, 0.7917, 0.7917]]\n",
      "[[899, 'ExtraTreesClassifier', 0.5769, 0.6455, 0.5333, 0.5333, 0.6455, 0.4048, 0.3], [899, 'GradientBoostingClassifier', 0.5, 0.6429, 0.6429, 0.6429, 0.6429, 0.75, 0.75], [899, 'RandomForestClassifier', 0.5769, 0.75, 0.75, 0.5769, 0.5769, 0.5769, 0.5769]]\n"
     ]
    }
   ],
   "source": [
    "seed_generator = Utilities.generate_pi_seed(20)\n",
    "seed_vals = [next(seed_generator) for i in range(20)]\n",
    "shake_percentages = [0.2, 0.4, 0.6]\n",
    "circle_methods = ['on', 'in']\n",
    "ml_models = [ExtraTreesClassifier(), GradientBoostingClassifier(), RandomForestClassifier()]\n",
    "scaler = MinMaxScaler((0, 1))\n",
    "\n",
    "distance_results = [[\"seed\", \"on_20%_dist\", \"on_20%_std\", \"on_40%_dist\", \"on_40%_std\", \"on_60%_dist\", \"on_60%_std\",\n",
    "                    \"in_20%_dist\",\"in_20%_std\",\"in_40%_dist\",\"in_40%_std\",\"in_60%_dist\",\"in_60%_std\"]]\n",
    "\n",
    "model_results = [[\"seed\", \"model\", \"baseline\", \"in_20%_f1\", \"in_40%_f1\", \"in_60%_f1\", \"on_20%_f1\", \"on_40%_f1\", \"on_60%_f1\"]]\n",
    "\n",
    "for seed in seed_vals:\n",
    "    # Intermediate lists for storing distance and model score values.\n",
    "    distance_row = [seed]\n",
    "\n",
    "    # Set apart 20% data for testing that augmentation process will never see.\n",
    "    train, test_x, test_y = TestUtils.get_test_train_data(dataset=ready_dataset, seed_val=seed,\n",
    "                                                          class_col='mode_of_transport', k=0.8)\n",
    "\n",
    "    model_row = TestUtils.create_model_row(seed, ml_models, \"mode_of_transport\", train, test_x, test_y)\n",
    "    for shake in shake_percentages:\n",
    "        for method in circle_methods:\n",
    "            # Randomly select 30% of trajectories to be augmented.\n",
    "            selected = Selection.select_randomly(train, seed, k=0.3)\n",
    "\n",
    "            # Augment the trajectories.\n",
    "            train_x, train_y = TestUtils.augment_trajectories_using_random_strategy(dataset=train,\n",
    "                                                                                    percent_to_shake=shake,\n",
    "                                                                                    ids_to_augment=selected,\n",
    "                                                                                    circle=method,\n",
    "                                                                                    n_augmentations=20,\n",
    "                                                                                    class_col=\"mode_of_transport\")\n",
    "            mean, std = TestUtils.find_original_and_augmentation_pairs_and_calculate_differences(train_x, selected)\n",
    "            distance_row.append(mean)\n",
    "            distance_row.append(std)\n",
    "\n",
    "            for i in range(len(ml_models)):\n",
    "                f1_score = TestUtils.train_model_and_evaluate(ml_models[i], scaler.fit_transform(train_x), train_y,\n",
    "                                                              scaler.fit_transform(test_x), test_y, seed)\n",
    "                model_row[i].append(f1_score)\n",
    "\n",
    "    model_results.extend(model_row)\n",
    "    distance_results.append(distance_row)\n",
    "\n",
    "    print(model_row)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-27T04:36:06.950914295Z",
     "start_time": "2023-08-24T20:56:09.225958485Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File successfully written to: ./geolife_distances.csv\n",
      "File successfully written to: ./geolife_f1_score.csv\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "\n",
    "file_path = \"./geolife_distances.csv\"\n",
    "with open(file_path, mode=\"w\") as file:\n",
    "    writer = csv.writer(file)\n",
    "    for item in distance_results:\n",
    "        writer.writerow(item)\n",
    "    print(f\"File successfully written to: {file_path}\")\n",
    "\n",
    "file_path = \"./geolife_f1_score.csv\"\n",
    "with open(file_path, mode=\"w\") as file:\n",
    "    writer = csv.writer(file)\n",
    "    for item in model_results:\n",
    "        writer.writerow(item)\n",
    "    print(f\"File successfully written to: {file_path}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-27T04:36:06.953125883Z",
     "start_time": "2023-08-27T04:36:06.949466335Z"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
