{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bba5a4d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "686bdbad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from random import *\n",
    "\n",
    "import pandas as pd\n",
    "import progressbar\n",
    "from ptrail.core.TrajectoryDF import PTRAILDataFrame\n",
    "from ptrail.features.kinematic_features import KinematicFeatures\n",
    "from ptrail.preprocessing.statistics import Statistics\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "from src.augmentation.augment import Augmentation\n",
    "from src.selection.select import Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "feabcff9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def trajectoryAugumentationProcedure(trajs, seed, class_name, selection, augment):\n",
    "#     myRandom = Random(seed)\n",
    "#\n",
    "#     # Select the trajectories and remove duplicates from original dataset.\n",
    "#     if selection == 'random':\n",
    "#         splits = Selection.select_randomly(trajs, myRandom, .2)\n",
    "#     elif selection == 'proportional':\n",
    "#         splits = Selection.select_trajectories_proportionally(trajs, myRandom, .2)\n",
    "#     elif selection == 'class':\n",
    "#         splits = Selection.select_fewest_class(trajs, class_name, myRandom)\n",
    "#\n",
    "#     paramTestingDataSet = Filters.remove_duplicates(dataframe=trajs)\n",
    "#\n",
    "#     trainDataParm = paramTestingDataSet.loc[paramTestingDataSet.traj_id.isin(splits[\"train\"]) == True].dropna()\n",
    "#     testDataParm = paramTestingDataSet.loc[paramTestingDataSet.traj_id.isin(splits[\"test\"]) == True].dropna()\n",
    "#     testData = PTRAILDataFrame(data_set=testDataParm,\n",
    "#                                latitude='lat',\n",
    "#                                longitude='lon',\n",
    "#                                datetime='DateTime',\n",
    "#                                traj_id='traj_id')\n",
    "#\n",
    "#     statsTestParm = Statistics.generate_kinematic_stats(dataframe=testData, target_col_name=class_name)\n",
    "#     pivotedStatsTestParm = Statistics.pivot_stats_df(dataframe=statsTestParm, target_col_name=class_name)\n",
    "#     pivotedStatsTestParm = pivotedStatsTestParm.loc[:,~pivotedStatsTestParm.columns.duplicated()]\n",
    "#     testParmX = pivotedStatsTestParm.drop(columns=class_name)\n",
    "#     testParmY = pivotedStatsTestParm[class_name].to_numpy()\n",
    "#     noiseTraj = trainDataParm.traj_id.unique()\n",
    "#\n",
    "#     sampledTraj = myRandom.choices(sorted(noiseTraj), k=math.floor(len(noiseTraj)))\n",
    "#     for traj in sampledTraj:\n",
    "#         trajToChange = trainDataParm.loc[trainDataParm.traj_id == traj]\n",
    "#         #Trajectory must be changed\n",
    "#         if augment == 'on':\n",
    "#             trajChanged = Augmentation.augment_trajectories_with_randomly_generated_points(trajToChange, myRandom, 'on')\n",
    "#         elif augment == 'in':\n",
    "#             trajChanged = Augmentation.augment_trajectories_with_randomly_generated_points(trajToChange, myRandom, 'in')\n",
    "#\n",
    "#         trainDataParm = pd.concat([trainDataParm, trajChanged], ignore_index = True)\n",
    "#\n",
    "#     trainDataNoise = PTRAILDataFrame(data_set=trainDataParm,\n",
    "#                                             datetime='DateTime',\n",
    "#                                             traj_id='traj_id',\n",
    "#                                             latitude='lat',\n",
    "#                                             longitude='lon')\n",
    "#\n",
    "#     statsTrainNoiseParm = Statistics.generate_kinematic_stats(dataframe=trainDataNoise, target_col_name=class_name)\n",
    "#     pivotedStatsTrainNoiseParm = Statistics.pivot_stats_df(dataframe=statsTrainNoiseParm, target_col_name=class_name)\n",
    "#     pivotedStatsTrainNoise = pivotedStatsTrainNoiseParm.loc[:, ~pivotedStatsTrainNoiseParm.columns.duplicated()]\n",
    "#     pivotedStatsTrainNoise=pivotedStatsTrainNoise.dropna()\n",
    "#\n",
    "#     trainParmX = pivotedStatsTrainNoise.drop(columns=class_name)\n",
    "#     trainParmY = pivotedStatsTrainNoise[class_name].to_numpy()\n",
    "#\n",
    "#     # Why is this interpolated?\n",
    "#     testParmX = testParmX.interpolate()\n",
    "#     return [trainParmX, trainParmY, testParmX, testParmY]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "def augment_and_create_train_test_splits(trajs, seed, class_name, selection, augment, augment_percent):\n",
    "    myRandom = Random(seed)\n",
    "\n",
    "    # Select the trajectories and remove duplicates from original dataset.\n",
    "    if selection == 'random':\n",
    "        splits = Selection.select_randomly(trajs, myRandom, .2)\n",
    "    elif selection == 'proportional':\n",
    "        splits = Selection.select_trajectories_proportionally(trajs, myRandom, .2)\n",
    "    elif selection == 'fewest':\n",
    "        splits = Selection.select_fewest_class(trajs, class_name, myRandom)\n",
    "    unique_data = trajs.drop_duplicates(subset=['DateTime', 'traj_id', 'lat', 'lon'],\n",
    "            keep='first')\n",
    "\n",
    "    # Split the original data into training and testing sets as per the splits created above.\n",
    "    unique_training_data = unique_data.loc[unique_data['traj_id'].isin(splits['train'])].dropna()\n",
    "    unique_testing_data = unique_data.loc[unique_data['traj_id'].isin(splits['test'])].dropna()\n",
    "\n",
    "    # Randomly select the trajectories to be augmented and then\n",
    "    # perform the augmentation procedure.\n",
    "    # TODO: Also, why are we augmenting all the trajectories here?\n",
    "    traj_ids = unique_training_data['traj_id'].unique()\n",
    "    selected_trajectories = myRandom.choices(sorted(traj_ids), k=math.floor(augment_percent * len(traj_ids)))\n",
    "    for traj in selected_trajectories:\n",
    "        current_traj = unique_training_data.loc[unique_training_data.traj_id == traj]\n",
    "        #Trajectory must be changed\n",
    "        if augment == 'on':\n",
    "            augmented_traj = Augmentation.augment_trajectories_with_randomly_generated_points(current_traj, myRandom, 'on')\n",
    "        elif augment == 'in':\n",
    "            augmented_traj = Augmentation.augment_trajectories_with_randomly_generated_points(current_traj, myRandom, 'in')\n",
    "        unique_training_data = pd.concat([unique_training_data, augmented_traj])\n",
    "\n",
    "    # Create the training X and Y values.\n",
    "    X_train = Statistics.pivot_stats_df(Statistics.generate_kinematic_stats(unique_training_data, class_name),\n",
    "                                        class_name)\n",
    "    Y_train = X_train[class_name].to_numpy()\n",
    "\n",
    "    # Create the testing X and Y values.\n",
    "    X_test = Statistics.pivot_stats_df(Statistics.generate_kinematic_stats(unique_testing_data, class_name),\n",
    "                                       class_name)\n",
    "    Y_test = X_test[class_name].to_numpy()\n",
    "\n",
    "    # Drop the target column and return the training and testing splits.\n",
    "    return [X_train.drop(columns=[class_name]).to_numpy(), Y_train,\n",
    "            X_test.drop(columns=[class_name]).to_numpy(), Y_test]\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "07d854e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "array(['880109D01', '880119D02', '880120D02', '890130D09', '890221E02',\n       '890222E01', '890224E04', '890317E01', '890317E23', '890317E25',\n       '890324E17', '890328E12', '890328E21', '890328E34', '890413E05',\n       '890418E01', '890418E04', '890418E13', '890418E15', '890424E06',\n       '890424E08', '890504E01', '900205E01', '900205E11', '900205E14',\n       '900219E15', '900313D02', '900626E01', '910130D01', '910214D01',\n       '910301D01', '910312E05', '910312E09', '910312E12', '910312E13',\n       '910313E07', '910313E11', '910313E18', '910313E19', '910313E26',\n       '910313E37', '910315E04', '910315E08', '910315E14', '910315E15',\n       '910315E17', '910315E20', '910315E22', '910319E02', '910319E11',\n       '920122D01', '920125E01', '920225D01', '920226D01', '920303D05',\n       '920304D03', '920309D02', '920318D02', '921123E22', '921130E09',\n       '921130E30', '921215E02', '921216E02', '921216E04', '921216E08',\n       '921228E02', '921228E04', '921228E06', '921228E09', '921228E12',\n       '921228E16', '921228E19', '921228E34', '921230E03', '930104E05',\n       '930107E06', '930107E08', '930107E09', '930119E02', '930119E03',\n       '930120D04', '930127D01', '930202D01', '930202E03', '930202E07',\n       '930202E16', '930203E01', '930203E03', '930203E06', '930209E06',\n       '930209E08', '930216E01', '930216E05', '930218D01', '930304E05',\n       '930304E06', '930304E13', '930304E16', '930318D01', '930318D03',\n       '930318D04', '930406D01', '930408E03', '930408E08', '930409D01',\n       '930409E04', '930410E01', '930410E04', '930415D02', '930415E02',\n       '930415E04', '930416D01', '930417E01', '930421E03', '930422E04',\n       '930429E01', '930429E08', '931215E09', '931216E09', '940105D01',\n       '940105D02', '940110D01', '940117D02', '940119D01', '940124D01',\n       '940131D01', '940205D01', '940212D01', '940213D01', '940213E01',\n       '940215D01', '940215E02', '940217D01', '940219E02', '940219E06',\n       '940219E07', '940219E10', '940219E11', '940219E12', '940221E07',\n       '940222D01', '940228E01', '940303D01', '940316D01', '940318D01',\n       '940329E01', '940413E01', '941128E01', '941129E04', '941220E01',\n       '941220E05', '941220E09', '941221E06', '941221E14', '941222E03',\n       '941227E01', '950104E02', '950104E04', '950104E07', '950124D01',\n       '950124D02', '950124E01', '950125E01', '950125E10', '950125E13',\n       '950126D01', '950227D02', '950308D03', '950313D01', '950405E12',\n       '950415E01', '950418E01', '960121D01', '960127D01', '960131D02',\n       '960131E12', '960227E09', '960313E02', '960313E04', 'OSUX83041',\n       'OSUX83061', 'OSUX85078', 'OSUX85135', 'OSUX85159', 'OSUX86137',\n       'OSUX87130', 'OSUX87175', 'OSUX87188', 'OSUX87190', 'OSUX88123',\n       'OSUX88129', 'OSUX88134', 'OSUX88159', 'OSUX88169', 'OSUX88176',\n       'OSUX89065', 'OSUX89073', 'OSUX89078', 'OSUX89086', 'OSUX89087',\n       'OSUX89105', 'OSUX89116', 'OSUX89125', 'OSUX89127', 'OSUX89128',\n       'OSUX89132', 'OSUX89136', 'OSUX89141', 'OSUX89146', 'OSUX89153',\n       'OSUX89177', 'OSUX89189', 'OSUX89199', 'OSUX89203', 'OSUX89208',\n       'OSUX91032', 'OSUX91038', 'OSUX91057', 'OSUX91063', 'OSUX91066',\n       'OSUX91073', 'OSUX91075', 'OSUX91092', 'OSUX91095', 'OSUX91116',\n       'OSUX91121', 'OSUX91143', 'OSUX91164', 'OSUX92002', 'OSUX92008',\n       'OSUX92013', 'OSUX92014', 'OSUX92016', 'OSUX92020', 'OSUX92031',\n       'OSUX92035', 'OSUX92061', 'OSUX92069', 'OSUX92070', 'OSUX92071',\n       'OSUX92083', 'OSUX92107', 'OSUX92115', 'OSUX93007', 'OSUX93039',\n       'OSUX93041', 'OSUX93046', 'OSUX93066', 'OSUX93091', 'OSUX93110',\n       'OSUX93123', 'OSUX93151', 'OSUX93191'], dtype=object)"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = PTRAILDataFrame(pd.read_csv('./starkey.csv'), traj_id='traj_id',\n",
    "                          datetime='DateTime', latitude='lat', longitude='lon')\n",
    "ready_dataset = KinematicFeatures.create_distance_column(dataset)\n",
    "\n",
    "ready_dataset.reset_index(inplace=True)\n",
    "ready_dataset.reset_index().traj_id.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46da1e90",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# seed_vals = [14159, 26535, 89793]\n",
    "# selection_vals = ['random', 'class', 'proportional']\n",
    "# augment_vals = ['on', 'in']\n",
    "\n",
    "seed_vals = [14159]\n",
    "selection_vals = ['random', 'fewest', 'proportional']\n",
    "augment_vals = ['on']\n",
    "augment_percents = [0.2]\n",
    "\n",
    "i = 0\n",
    "lst = []\n",
    "bar = progressbar.ProgressBar(max_value=progressbar.UnknownLength)\n",
    "for s in seed_vals:\n",
    "    for sel in selection_vals:\n",
    "        for aug in augment_vals:\n",
    "            for percent in augment_percents:\n",
    "                bar.update(i)\n",
    "                i += 1\n",
    "                # Create the model.\n",
    "                model = RandomForestClassifier(random_state=s)\n",
    "\n",
    "                # Get the augmented data.\n",
    "                data = augment_and_create_train_test_splits(ready_dataset, s, 'Species', sel, aug, percent)\n",
    "\n",
    "                # Fit the model and perform testing.\n",
    "                model.fit(data[0], data[1])\n",
    "                test_predict = model.predict(data[2])\n",
    "                performance_val = f1_score(data[3], test_predict, average='weighted')\n",
    "                # Add the value to dict.\n",
    "                lst.append(f\"{s}, {sel}, {aug}, {percent}, {performance_val}\")\n",
    "\n",
    "print(lst)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
