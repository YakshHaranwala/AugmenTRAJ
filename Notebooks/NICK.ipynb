{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/home/nicholasjesperson/Documents/School/Comp4780/Data_Augmentation/Data Augmentation/paper/AugmenTRAJ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "from src.augmentation.augment import Augmentation\n",
    "from src.selection.select import Selection\n",
    "from src.utils.alter import Alter\n",
    "import math\n",
    "import pandas as pd\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import f1_score\n",
    "from random import *\n",
    "from ptrail.core.TrajectoryDF import PTRAILDataFrame\n",
    "from ptrail.preprocessing.filters import Filters\n",
    "from ptrail.core.Datasets import Datasets\n",
    "from ptrail.preprocessing.statistics import Statistics\n",
    "from ptrail.features.kinematic_features import KinematicFeatures\n",
    "\n",
    "# pd.set_option('use_inf_as_na', True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def trajectoryAugumentationProcedure(trajs, seed, n, k, pradius, model):\n",
    "    myRandom = Random(seed * (n * k * pradius))\n",
    "\n",
    "    #Split data must be changed\n",
    "    # splits = Selection.select_randomly(trajs, .2)\n",
    "    splits = Selection.select_traj_with_fewest(trajs, myRandom, .2)\n",
    "    # splits = Selection.select_representative_trajectories(trajs, 'VesselType')\n",
    "\n",
    "    paramTestingDataSet = Filters.remove_duplicates(dataframe=trajs)\n",
    "\n",
    "    trainDataParm = paramTestingDataSet.loc[paramTestingDataSet.traj_id.isin(splits[\"train\"]) == True].dropna()\n",
    "    testDataParm = paramTestingDataSet.loc[paramTestingDataSet.traj_id.isin(splits[\"test\"]) == True].dropna()\n",
    "    testData = PTRAILDataFrame(data_set=testDataParm,\n",
    "                               latitude='lat',\n",
    "                               longitude='lon',\n",
    "                               datetime='DateTime',\n",
    "                               traj_id='traj_id')\n",
    "    statsTestParm = Statistics.generate_kinematic_stats(dataframe=testData,\n",
    "                                                target_col_name='Status')\n",
    "    pivotedStatsTestParm = Statistics.pivot_stats_df(dataframe=statsTestParm,\n",
    "                                              target_col_name='Status')\n",
    "    pivotedStatsTestParm = pivotedStatsTestParm.loc[:,~pivotedStatsTestParm.columns.duplicated()]\n",
    "    testParmX = pivotedStatsTestParm.drop(columns='Status')\n",
    "    testParmY = pivotedStatsTestParm['Status'].to_numpy()\n",
    "    noiseTraj = trainDataParm['traj_id'].unique()\n",
    "\n",
    "    sampledTraj = myRandom.choices(sorted(noiseTraj), k=math.floor(n * len(noiseTraj)))\n",
    "    for traj in sampledTraj:\n",
    "        trajToChange = trainDataParm.loc[trainDataParm.traj_id == traj]\n",
    "\n",
    "\n",
    "\n",
    "        #Trajectory must be changed\n",
    "        # trajChanged = Augmentation.augment_trajectories_with_randomly_generated_points(trajToChange, pradius,\n",
    "        #                                                                              k, 100, myRandom, 'on')\n",
    "        # trajChanged = Augmentation.augment_trajectories_with_randomly_generated_points(trajToChange, pradius,\n",
    "        #                                                                               k, 100, myRandom, 'in')\n",
    "        trajChanged = Augmentation.augment_trajectories_with_interpolation(trajToChange, 3600*4, 'cubic')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        trainDataParm = pd.concat([trainDataParm, trajChanged], ignore_index = True)\n",
    "\n",
    "    #trainDataNoiseFilt = trainDataParm.filter([\"traj_id\", \"DateTime\",\"vehicle_type\", \"velocity\" ,\"VesselType\" \"lon\", \"lat\", \"kilopost\",\"vehicle_length\", \"detected_flag\"])\n",
    "\n",
    "\n",
    "\n",
    "    trainDataNoise = PTRAILDataFrame(data_set=trainDataParm,\n",
    "                                            datetime='DateTime',\n",
    "                                            traj_id='traj_id',\n",
    "                                            latitude='lat',\n",
    "                                            longitude='lon')\n",
    "\n",
    "    statsTrainNoiseParm = Statistics.generate_kinematic_stats(dataframe=trainDataNoise,\n",
    "                                                        target_col_name='Status')\n",
    "\n",
    "    pivotedStatsTrainNoiseParm = Statistics.pivot_stats_df(dataframe=statsTrainNoiseParm,\n",
    "                                                      target_col_name='Status')\n",
    "\n",
    "    pivotedStatsTrainNoise = pivotedStatsTrainNoiseParm.loc[:,~pivotedStatsTrainNoiseParm.columns.duplicated()]\n",
    "\n",
    "\n",
    "    pivotedStatsTrainNoise=pivotedStatsTrainNoise.dropna()\n",
    "\n",
    "    trainParmX = pivotedStatsTrainNoise.drop(columns='Status')\n",
    "    trainParmY = pivotedStatsTrainNoise['Status'].to_numpy()\n",
    "\n",
    "    testParmX = testParmX.interpolate()\n",
    "\n",
    "    model.fit(trainParmX, trainParmY)\n",
    "    test_predict = model.predict(testParmX)\n",
    "    performance_val = f1_score(testParmY, test_predict, average='weighted')\n",
    "    print(f\"Current run: k={k}, pradius={pradius}, n={n}, fscore={performance_val}, seed={seed}\")\n",
    "    return str(f\"{n},{k},{pradius},{performance_val}\\n\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "dataset = Datasets.load_hurricanes()\n",
    "ready_dataset = Filters.remove_duplicates(dataframe=dataset)\n",
    "\n",
    "seeds = [14159,26535,89793]\n",
    "n_vals = [.2, .3, .4]\n",
    "k_vals = [.1, .2, .3]\n",
    "rad_vals = [.001, .005, .01]\n",
    "\n",
    "\n",
    "#Rename results file to name of tests run\n",
    "text_file = open(\"./Hurricane Results/HurricanesFewestSamplesInterpolation.txt\", \"w\")\n",
    "for n in n_vals:\n",
    "    for k in k_vals:\n",
    "        for rad in rad_vals:\n",
    "            for s in seeds:\n",
    "                result = (trajectoryAugumentationProcedure(ready_dataset, s, n, k,\n",
    "                                                       rad, RandomForestClassifier(random_state=s)))\n",
    "                # print(result)\n",
    "                text_file.writelines(result)\n",
    "text_file.close()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}