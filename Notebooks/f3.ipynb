{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from src.augmentation.augment import Augmentation\n",
    "from src.selection.select import Selection\n",
    "from src.utils.alter import Alter\n",
    "import math\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from random import *\n",
    "from ptrail.core.TrajectoryDF import PTRAILDataFrame\n",
    "from ptrail.preprocessing.filters import Filters\n",
    "from ptrail.core.Datasets import Datasets\n",
    "from ptrail.preprocessing.statistics import Statistics\n",
    "from ptrail.features.kinematic_features import KinematicFeatures\n",
    "import progressbar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "def trajectoryAugumentationProcedure(trajs, seed, n, k, pradius, class_name, selection, augment):\n",
    "    myRandom = Random(seed * (n * k * pradius))\n",
    "\n",
    "    # Select the trajectories and remove duplicates from original dataset.\n",
    "    if selection == 'random':\n",
    "        splits = Selection.select_randomly(trajs, myRandom, .2)\n",
    "    elif selection == 'fewest':\n",
    "        splits = Selection.select_traj_with_fewest(trajs, myRandom, .2)\n",
    "    else:\n",
    "        splits = Selection.select_representative_trajectories(trajs, class_name)\n",
    "    paramTestingDataSet = Filters.remove_duplicates(dataframe=trajs)\n",
    "\n",
    "    trainDataParm = paramTestingDataSet.loc[paramTestingDataSet.traj_id.isin(splits[\"train\"]) == True].dropna()\n",
    "    testDataParm = paramTestingDataSet.loc[paramTestingDataSet.traj_id.isin(splits[\"test\"]) == True].dropna()\n",
    "    testData = PTRAILDataFrame(data_set=testDataParm,\n",
    "                               latitude='lat',\n",
    "                               longitude='lon',\n",
    "                               datetime='DateTime',\n",
    "                               traj_id='traj_id')\n",
    "\n",
    "    statsTestParm = Statistics.generate_kinematic_stats(dataframe=testData, target_col_name=class_name)\n",
    "    pivotedStatsTestParm = Statistics.pivot_stats_df(dataframe=statsTestParm, target_col_name=class_name)\n",
    "    pivotedStatsTestParm = pivotedStatsTestParm.loc[:,~pivotedStatsTestParm.columns.duplicated()]\n",
    "    testParmX = pivotedStatsTestParm.drop(columns=class_name)\n",
    "    testParmY = pivotedStatsTestParm[class_name].to_numpy()\n",
    "    noiseTraj = trainDataParm.traj_id.unique()\n",
    "\n",
    "    sampledTraj = myRandom.choices(sorted(noiseTraj), k=math.floor(n * len(noiseTraj)))\n",
    "    for traj in sampledTraj:\n",
    "        trajToChange = trainDataParm.loc[trainDataParm.traj_id == traj]\n",
    "\n",
    "        #Trajectory must be changed\n",
    "        if augment == 'on':\n",
    "            trajChanged = Augmentation.augment_trajectories_with_randomly_generated_points(trajToChange, pradius,\n",
    "                                                                                         k, 100, myRandom, 'on')\n",
    "        elif augment == 'in':\n",
    "            trajChanged = Augmentation.augment_trajectories_with_randomly_generated_points(trajToChange, pradius,\n",
    "              -                                                                            k, 100, myRandom, 'in')\n",
    "        else:\n",
    "            trajChanged = Augmentation.augment_trajectories_with_interpolation(trajToChange, 3600*4, 'cubic')\n",
    "        trainDataParm = pd.concat([trainDataParm, trajChanged], ignore_index = True)\n",
    "\n",
    "    trainDataNoise = PTRAILDataFrame(data_set=trainDataParm,\n",
    "                                            datetime='DateTime',\n",
    "                                            traj_id='traj_id',\n",
    "                                            latitude='lat',\n",
    "                                            longitude='lon')\n",
    "\n",
    "    statsTrainNoiseParm = Statistics.generate_kinematic_stats(dataframe=trainDataNoise, target_col_name=class_name)\n",
    "    pivotedStatsTrainNoiseParm = Statistics.pivot_stats_df(dataframe=statsTrainNoiseParm, target_col_name=class_name)\n",
    "    pivotedStatsTrainNoise = pivotedStatsTrainNoiseParm.loc[:, ~pivotedStatsTrainNoiseParm.columns.duplicated()]\n",
    "    pivotedStatsTrainNoise=pivotedStatsTrainNoise.dropna()\n",
    "\n",
    "    trainParmX = pivotedStatsTrainNoise.drop(columns=class_name)\n",
    "    trainParmY = pivotedStatsTrainNoise[class_name].to_numpy()\n",
    "\n",
    "    testParmX = testParmX.interpolate()\n",
    "    return [trainParmX, trainParmY, testParmX, testParmY]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------ Dataset Facts ------------------------------\n",
      "\n",
      "Number of unique Trajectories in the data: 253\n",
      "Number of points in the data: 287136\n",
      "Dataset time range: 1196 days 22:51:45\n",
      "Datatype of the DataFrame: <class 'ptrail.core.TrajectoryDF.PTRAILDataFrame'>\n",
      "Dataset Bounding Box: (45.18896978643169, -118.61020848239596, 45.314545642992, -118.50455596234036)\n",
      "\n",
      "---------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "dataset = Datasets.load_starkey()\n",
    "ready_dataset = Filters.remove_duplicates(dataframe=dataset)\n",
    "\n",
    "# Do test train split to take out a validation set for the end.\n",
    "X_train, X_test, y_train, y_test = train_test_split(ready_dataset.drop(columns=['Species']),\n",
    "                                                    ready_dataset['Species'], test_size=0.2, random_state=42)\n",
    "X_train['Status'] = y_train"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/ |                     #                          | 729 Elapsed Time: 20:23:00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 15h 32min 42s, sys: 1h 33s, total: 16h 33min 16s\n",
      "Wall time: 20h 25min 43s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "seed_vals = [14159, 26535, 89793]\n",
    "n_vals = [.2, .3, .4]\n",
    "k_vals = [.1, .2, .3]\n",
    "rad_vals = [.001, .005, .01]\n",
    "selection_vals = ['random', 'fewest', 'representative']\n",
    "augment_vals = ['on', 'in', 'interpolate']\n",
    "\n",
    "i = 0\n",
    "bar = progressbar.ProgressBar(max_value=progressbar.UnknownLength)\n",
    "text_file = open(\"./Final Results/FinalStarkeyResults.csv\", \"w\")\n",
    "for s in seed_vals:\n",
    "    for n in n_vals:\n",
    "        for k in k_vals:\n",
    "            for rad in rad_vals:\n",
    "                for sel in selection_vals:\n",
    "                    for aug in augment_vals:\n",
    "                        i += 1\n",
    "                        bar.update(i)\n",
    "                        # Create the model.\n",
    "                        model = RandomForestClassifier(random_state=s)\n",
    "\n",
    "                        # Get the augmented data.\n",
    "                        data = trajectoryAugumentationProcedure(ready_dataset, s, n, k, rad, 'Species', sel, aug)\n",
    "\n",
    "                        # Fit the model and perform testing.\n",
    "                        model.fit(data[0], data[1])\n",
    "                        test_predict = model.predict(data[2])\n",
    "                        performance_val = f1_score(data[3], test_predict, average='weighted')\n",
    "                        # Add the value to dict.\n",
    "                        text_file.writelines(f\"{s},{n},{k},{rad},{sel},{aug},{performance_val}\\n\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}