{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bba5a4d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path\n",
    "sys.path.append('/home/nicholasjesperson/Documents/School/Comp4780/Data_Augmentation/Data Augmentation/paper/AugmenTRAJ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "686bdbad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.augmentation.augment import Augmentation\n",
    "from src.selection.select import Selection\n",
    "from src.utils.alter import Alter\n",
    "import math\n",
    "import pandas as pd\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import f1_score\n",
    "from random import *\n",
    "from ptrail.core.TrajectoryDF import PTRAILDataFrame\n",
    "from ptrail.preprocessing.filters import Filters\n",
    "from ptrail.core.Datasets import Datasets\n",
    "from ptrail.preprocessing.statistics import Statistics\n",
    "from ptrail.features.kinematic_features import KinematicFeatures\n",
    "\n",
    "pd.set_option('use_inf_as_na', True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "867f222b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def trajectoryAugumentationProcedure(trajs, seed, n, k, pradius, model):\n",
    "    myRandom = Random(seed * (n * k * pradius))\n",
    "    \n",
    "    \n",
    "    \n",
    "    #Split data must be changed\n",
    "    #splits = Selection.select_randomly(trajs, .2)\n",
    "    splits = Selection.select_traj_with_fewest(trajs, myRandom, .2)\n",
    "    #splits = Selection.select_representative_trajectories(trajs, 'traffic_lane')\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    paramTestingDataSet = Filters.remove_duplicates(dataframe=trajs)\n",
    "\n",
    "    trainDataParm = paramTestingDataSet.loc[paramTestingDataSet.traj_id.isin(splits[\"train\"]) == True].dropna()\n",
    "    testDataParm = paramTestingDataSet.loc[paramTestingDataSet.traj_id.isin(splits[\"test\"]) == True].dropna()\n",
    "    testData = PTRAILDataFrame(data_set=testDataParm,\n",
    "                               latitude='lat',\n",
    "                               longitude='lon',\n",
    "                               datetime='DateTime',\n",
    "                               traj_id='traj_id')\n",
    "    statsTestParm = Statistics.generate_kinematic_stats(dataframe=testData,\n",
    "                                                target_col_name='traffic_lane')\n",
    "    pivotedStatsTestParm = Statistics.pivot_stats_df(dataframe=statsTestParm,\n",
    "                                              target_col_name='traffic_lane')\n",
    "    pivotedStatsTestParm = pivotedStatsTestParm.loc[:,~pivotedStatsTestParm.columns.duplicated()]\n",
    "    testParmX = pivotedStatsTestParm.drop(columns='traffic_lane')\n",
    "    testParmY = pivotedStatsTestParm['traffic_lane'].to_numpy()\n",
    "    noiseTraj = trainDataParm['traj_id'].unique()\n",
    "\n",
    "    sampledTraj = myRandom.choices(sorted(noiseTraj), k=math.floor(n * len(noiseTraj)))\n",
    "    for traj in sampledTraj:\n",
    "        trajToChange = trainDataParm.loc[trainDataParm.traj_id == traj]\n",
    "    \n",
    "    \n",
    "    \n",
    "        #Trajectory must be changed\n",
    "        #rajChanged = Augmentation.augment_trajectories_with_randomly_generated_points(trajToChange, pradius,\n",
    "        #                                                                              k, 100, myRandom, 'on')\n",
    "        #trajChanged = Augmentation.augment_trajectories_with_randomly_generated_points(trajToChange, pradius,\n",
    "        #                                                                               k, 100, myRandom, 'in')\n",
    "        trajChanged = Augmentation.augment_trajectories_with_interpolation(trajToChange, 3600*4, 'linear')\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        trainDataParm = pd.concat([trainDataParm, trajChanged], ignore_index = True)\n",
    "\n",
    "    #trainDataNoiseFilt = trainDataParm.filter([\"traj_id\", \"DateTime\",\"vehicle_type\", \"velocity\" ,\"traffic_lane\" \"lon\", \"lat\", \"kilopost\",\"vehicle_length\", \"detected_flag\"])\n",
    "\n",
    "\n",
    "\n",
    "    trainDataNoise = PTRAILDataFrame(data_set=trainDataParm,\n",
    "                                            datetime='DateTime',\n",
    "                                            traj_id='traj_id',\n",
    "                                            latitude='lat',\n",
    "                                            longitude='lon')\n",
    "    \n",
    "    statsTrainNoiseParm = Statistics.generate_kinematic_stats(dataframe=trainDataNoise,\n",
    "                                                        target_col_name='traffic_lane')\n",
    "\n",
    "    pivotedStatsTrainNoiseParm = Statistics.pivot_stats_df(dataframe=statsTrainNoiseParm,\n",
    "                                                      target_col_name='traffic_lane')\n",
    "\n",
    "    pivotedStatsTrainNoise = pivotedStatsTrainNoiseParm.loc[:,~pivotedStatsTrainNoiseParm.columns.duplicated()]\n",
    "\n",
    "    \n",
    "    pivotedStatsTrainNoise=pivotedStatsTrainNoise.dropna()\n",
    "    \n",
    "    trainParmX = pivotedStatsTrainNoise.drop(columns='traffic_lane')\n",
    "    trainParmY = pivotedStatsTrainNoise['traffic_lane'].to_numpy()\n",
    "\n",
    "    testParmX = testParmX.dropna()\n",
    "    \n",
    "    model.fit(trainParmX, trainParmY)\n",
    "    test_predict = model.predict(testParmX)\n",
    "    performance_val = f1_score(testParmY, test_predict, average='weighted')\n",
    "    print(f\"Current run: k={k}, pradius={pradius}, n={n}, fscore={performance_val}, seed={seed}\")\n",
    "    return str(f\"{n},{k},{pradius},{performance_val}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "223daf66",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------ Dataset Facts ------------------------------\n",
      "\n",
      "Number of unique Trajectories in the data: 125\n",
      "Number of points in the data: 44905\n",
      "Dataset time range: 0 days 00:00:59.900000\n",
      "Datatype of the DataFrame: <class 'ptrail.core.TrajectoryDF.PTRAILDataFrame'>\n",
      "Dataset Bounding Box: (34.7107417, 135.4640652, 34.7156517, 135.4702002)\n",
      "\n",
      "---------------------------------------------------------------------\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [25, 24]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_1126178/1971386297.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mrad\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrad_vals\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0ms\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mseeds\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m                 result = (trajectoryAugumentationProcedure(ready_dataset, s, n, k,\n\u001b[0m\u001b[1;32m     17\u001b[0m                                                        rad, RandomForestClassifier(random_state=s)))\n\u001b[1;32m     18\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_1126178/2095176724.py\u001b[0m in \u001b[0;36mtrajectoryAugumentationProcedure\u001b[0;34m(trajs, seed, n, k, pradius, model)\u001b[0m\n\u001b[1;32m     77\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainParmX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainParmY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m     \u001b[0mtest_predict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtestParmX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 79\u001b[0;31m     \u001b[0mperformance_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf1_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtestParmY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_predict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maverage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'weighted'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     80\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Current run: k={k}, pradius={pradius}, n={n}, fscore={performance_val}, seed={seed}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{n},{k},{pradius},{performance_val}\\n\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/virtualEnv/lib/python3.9/site-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36mf1_score\u001b[0;34m(y_true, y_pred, labels, pos_label, average, sample_weight, zero_division)\u001b[0m\n\u001b[1;32m   1121\u001b[0m     \u001b[0mmodified\u001b[0m \u001b[0;32mwith\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mzero_division\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1122\u001b[0m     \"\"\"\n\u001b[0;32m-> 1123\u001b[0;31m     return fbeta_score(\n\u001b[0m\u001b[1;32m   1124\u001b[0m         \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1125\u001b[0m         \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/virtualEnv/lib/python3.9/site-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36mfbeta_score\u001b[0;34m(y_true, y_pred, beta, labels, pos_label, average, sample_weight, zero_division)\u001b[0m\n\u001b[1;32m   1259\u001b[0m     \"\"\"\n\u001b[1;32m   1260\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1261\u001b[0;31m     _, _, f, _ = precision_recall_fscore_support(\n\u001b[0m\u001b[1;32m   1262\u001b[0m         \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1263\u001b[0m         \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/virtualEnv/lib/python3.9/site-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36mprecision_recall_fscore_support\u001b[0;34m(y_true, y_pred, beta, labels, pos_label, average, warn_for, sample_weight, zero_division)\u001b[0m\n\u001b[1;32m   1542\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mbeta\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1543\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"beta should be >=0 in the F-beta score\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1544\u001b[0;31m     \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_set_wise_labels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maverage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpos_label\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1545\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1546\u001b[0m     \u001b[0;31m# Calculate tp_sum, pred_sum, true_sum ###\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/virtualEnv/lib/python3.9/site-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36m_check_set_wise_labels\u001b[0;34m(y_true, y_pred, average, labels, pos_label)\u001b[0m\n\u001b[1;32m   1346\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"average has to be one of \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maverage_options\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1347\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1348\u001b[0;31m     \u001b[0my_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_targets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1349\u001b[0m     \u001b[0;31m# Convert to Python primitive type to avoid NumPy type / Python str\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1350\u001b[0m     \u001b[0;31m# comparison. See https://github.com/numpy/numpy/issues/6784\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/virtualEnv/lib/python3.9/site-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36m_check_targets\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m     82\u001b[0m     \u001b[0my_pred\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0marray\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mindicator\u001b[0m \u001b[0mmatrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m     \"\"\"\n\u001b[0;32m---> 84\u001b[0;31m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     85\u001b[0m     \u001b[0mtype_true\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m     \u001b[0mtype_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/virtualEnv/lib/python3.9/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_consistent_length\u001b[0;34m(*arrays)\u001b[0m\n\u001b[1;32m    330\u001b[0m     \u001b[0muniques\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlengths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    331\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 332\u001b[0;31m         raise ValueError(\n\u001b[0m\u001b[1;32m    333\u001b[0m             \u001b[0;34m\"Found input variables with inconsistent numbers of samples: %r\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    334\u001b[0m             \u001b[0;34m%\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlengths\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [25, 24]"
     ]
    }
   ],
   "source": [
    "\n",
    "dataset = Datasets.load_traffic_data()\n",
    "ready_dataset = Filters.remove_duplicates(dataframe=dataset)\n",
    "\n",
    "seeds = [14159,26535,89793]\n",
    "n_vals = [.2, .3, .4]\n",
    "k_vals = [.1, .2, .3]\n",
    "rad_vals = [.001, .005, .01]\n",
    "\n",
    "\n",
    "#Rename results file to name of tests run\n",
    "text_file = open(\"laneResultsFewestSampleInterpolation.txt\", \"w\")\n",
    "for n in n_vals:\n",
    "    for k in k_vals:\n",
    "        for rad in rad_vals:\n",
    "            for s in seeds:\n",
    "                result = (trajectoryAugumentationProcedure(ready_dataset, s, n, k,\n",
    "                                                       rad, RandomForestClassifier(random_state=s)))\n",
    "                print(result)\n",
    "                text_file.writelines(result)\n",
    "text_file.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
