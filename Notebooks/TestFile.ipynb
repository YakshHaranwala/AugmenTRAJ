{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bba5a4d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import sys\n",
    "#sys.path.append('/home/nicholasjesperson/Documents/School/Comp4780/Data_Augmentation/Data Augmentation/paper/AugmenTRAJ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "686bdbad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from random import *\n",
    "\n",
    "import pandas as pd\n",
    "import progressbar\n",
    "from ptrail.core.TrajectoryDF import PTRAILDataFrame\n",
    "from ptrail.features.kinematic_features import KinematicFeatures\n",
    "from ptrail.preprocessing.statistics import Statistics\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "from src.augmentation.augment import Augmentation\n",
    "from src.selection.select import Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "feabcff9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def trajectoryAugumentationProcedure(trajs, seed, class_name, selection, augment):\n",
    "#     myRandom = Random(seed)\n",
    "#\n",
    "#     # Select the trajectories and remove duplicates from original dataset.\n",
    "#     if selection == 'random':\n",
    "#         splits = Selection.select_randomly(trajs, myRandom, .2)\n",
    "#     elif selection == 'proportional':\n",
    "#         splits = Selection.select_trajectories_proportionally(trajs, myRandom, .2)\n",
    "#     elif selection == 'class':\n",
    "#         splits = Selection.select_fewest_class(trajs, class_name, myRandom)\n",
    "#\n",
    "#     paramTestingDataSet = Filters.remove_duplicates(dataframe=trajs)\n",
    "#\n",
    "#     trainDataParm = paramTestingDataSet.loc[paramTestingDataSet.traj_id.isin(splits[\"train\"]) == True].dropna()\n",
    "#     testDataParm = paramTestingDataSet.loc[paramTestingDataSet.traj_id.isin(splits[\"test\"]) == True].dropna()\n",
    "#     testData = PTRAILDataFrame(data_set=testDataParm,\n",
    "#                                latitude='lat',\n",
    "#                                longitude='lon',\n",
    "#                                datetime='DateTime',\n",
    "#                                traj_id='traj_id')\n",
    "#\n",
    "#     statsTestParm = Statistics.generate_kinematic_stats(dataframe=testData, target_col_name=class_name)\n",
    "#     pivotedStatsTestParm = Statistics.pivot_stats_df(dataframe=statsTestParm, target_col_name=class_name)\n",
    "#     pivotedStatsTestParm = pivotedStatsTestParm.loc[:,~pivotedStatsTestParm.columns.duplicated()]\n",
    "#     testParmX = pivotedStatsTestParm.drop(columns=class_name)\n",
    "#     testParmY = pivotedStatsTestParm[class_name].to_numpy()\n",
    "#     noiseTraj = trainDataParm.traj_id.unique()\n",
    "#\n",
    "#     sampledTraj = myRandom.choices(sorted(noiseTraj), k=math.floor(len(noiseTraj)))\n",
    "#     for traj in sampledTraj:\n",
    "#         trajToChange = trainDataParm.loc[trainDataParm.traj_id == traj]\n",
    "#         #Trajectory must be changed\n",
    "#         if augment == 'on':\n",
    "#             trajChanged = Augmentation.augment_trajectories_with_randomly_generated_points(trajToChange, myRandom, 'on')\n",
    "#         elif augment == 'in':\n",
    "#             trajChanged = Augmentation.augment_trajectories_with_randomly_generated_points(trajToChange, myRandom, 'in')\n",
    "#\n",
    "#         trainDataParm = pd.concat([trainDataParm, trajChanged], ignore_index = True)\n",
    "#\n",
    "#     trainDataNoise = PTRAILDataFrame(data_set=trainDataParm,\n",
    "#                                             datetime='DateTime',\n",
    "#                                             traj_id='traj_id',\n",
    "#                                             latitude='lat',\n",
    "#                                             longitude='lon')\n",
    "#\n",
    "#     statsTrainNoiseParm = Statistics.generate_kinematic_stats(dataframe=trainDataNoise, target_col_name=class_name)\n",
    "#     pivotedStatsTrainNoiseParm = Statistics.pivot_stats_df(dataframe=statsTrainNoiseParm, target_col_name=class_name)\n",
    "#     pivotedStatsTrainNoise = pivotedStatsTrainNoiseParm.loc[:, ~pivotedStatsTrainNoiseParm.columns.duplicated()]\n",
    "#     pivotedStatsTrainNoise=pivotedStatsTrainNoise.dropna()\n",
    "#\n",
    "#     trainParmX = pivotedStatsTrainNoise.drop(columns=class_name)\n",
    "#     trainParmY = pivotedStatsTrainNoise[class_name].to_numpy()\n",
    "#\n",
    "#     # Why is this interpolated?\n",
    "#     testParmX = testParmX.interpolate()\n",
    "#     return [trainParmX, trainParmY, testParmX, testParmY]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "def augment_and_create_train_test_splits(trajs, seed, class_name, selection, augment, augment_percent):\n",
    "    myRandom = Random(seed)\n",
    "\n",
    "    # Select the trajectories and remove duplicates from original dataset.\n",
    "    if selection == 'random':\n",
    "        splits = Selection.select_randomly(trajs, myRandom, .2)\n",
    "    elif selection == 'proportional':\n",
    "        splits = Selection.select_trajectories_proportionally(trajs, myRandom, .2)\n",
    "    elif selection == 'fewest':\n",
    "        splits = Selection.select_fewest_class(trajs, class_name, myRandom)\n",
    "    unique_data = trajs.drop_duplicates(subset=['DateTime', 'traj_id', 'lat', 'lon'],\n",
    "            keep='first')\n",
    "\n",
    "    # Split the original data into training and testing sets as per the splits created above.\n",
    "    unique_training_data = unique_data.loc[unique_data['traj_id'].isin(splits['train'])].dropna()\n",
    "    unique_testing_data = unique_data.loc[unique_data['traj_id'].isin(splits['test'])].dropna()\n",
    "\n",
    "    # Randomly select the trajectories to be augmented and then\n",
    "    # perform the augmentation procedure.\n",
    "    # TODO: Also, why are we augmenting all the trajectories here?\n",
    "    traj_ids = unique_training_data['traj_id'].unique()\n",
    "    selected_trajectories = myRandom.choices(sorted(traj_ids), k=math.floor(augment_percent * len(traj_ids)))\n",
    "    for traj in selected_trajectories:\n",
    "        current_traj = unique_training_data.loc[unique_training_data.traj_id == traj]\n",
    "        #Trajectory must be changed\n",
    "        if augment == 'on':\n",
    "            augmented_traj = Augmentation.augment_trajectories_with_randomly_generated_points(current_traj, myRandom, 'on')\n",
    "        elif augment == 'in':\n",
    "            augmented_traj = Augmentation.augment_trajectories_with_randomly_generated_points(current_traj, myRandom, 'in')\n",
    "        unique_training_data = pd.concat([unique_training_data, augmented_traj])\n",
    "\n",
    "    # Create the training X and Y values.\n",
    "    X_train = Statistics.pivot_stats_df(Statistics.generate_kinematic_stats(unique_training_data, class_name),\n",
    "                                        class_name)\n",
    "    Y_train = X_train[class_name].to_numpy()\n",
    "\n",
    "    # Create the testing X and Y values.\n",
    "    X_test = Statistics.pivot_stats_df(Statistics.generate_kinematic_stats(unique_testing_data, class_name),\n",
    "                                       class_name)\n",
    "    Y_test = X_test[class_name].to_numpy()\n",
    "\n",
    "    # Drop the target column and return the training and testing splits.\n",
    "    return [X_train.drop(columns=[class_name]).to_numpy(), Y_train,\n",
    "            X_test.drop(columns=[class_name]).to_numpy(), Y_test]\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "07d854e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "          traj_id            DateTime        lat         lon  StarkeyTime  \\\n0       880109D01 1995-04-13 13:40:06  45.239682 -118.533204    229902006   \n1       880109D01 1995-04-15 12:16:15  45.250521 -118.530438    230069775   \n2       880109D01 1995-04-15 21:39:38  45.247943 -118.541455    230103578   \n3       880109D01 1995-04-16 03:32:14  45.247429 -118.539530    230124734   \n4       880109D01 1995-04-16 04:08:28  45.247117 -118.542579    230126908   \n...           ...                 ...        ...         ...          ...   \n287131  OSUX93191 1996-08-15 06:51:06  45.220642 -118.543392    272213466   \n287132  OSUX93191 1996-08-15 08:45:15  45.219785 -118.546807    272220315   \n287133  OSUX93191 1996-08-15 10:36:54  45.219801 -118.545661    272227014   \n287134  OSUX93191 1996-08-15 12:31:22  45.220268 -118.551024    272233882   \n287135  OSUX93191 1996-08-15 14:25:58  45.222562 -118.541151    272240758   \n\n          GMDate    GMTime   LocDate   LocTime  RadNum  Species    UTME  \\\n0       21:40:06  19950413  19950413  13:40:06     409        0  379662   \n1       20:16:15  19950415  19950415  12:16:15     409        0  379895   \n2       05:39:38  19950416  19950415  21:39:38     409        0  379039   \n3       11:32:14  19950416  19950416  03:32:14     409        0  379188   \n4       12:08:28  19950416  19950416  04:08:28     409        0  378938   \n...          ...       ...       ...       ...     ...      ...     ...   \n287131  14:51:06  19960815  19960815  06:51:06     390        2  378821   \n287132  16:45:15  19960815  19960815  08:45:15     390        2  378568   \n287133  18:36:54  19960815  19960815  10:36:54     390        2  378645   \n287134  20:31:22  19960815  19960815  12:31:22     390        2  378232   \n287135  22:25:58  19960815  19960815  14:25:58     390        2  378995   \n\n           UTMN  Year  Grensunr  Grensuns  Obswt     Distance  \n0       5010734    95  13:13:00  02:39:00   1.47          NaN  \n1       5011927    95  13:09:00  02:41:00   1.59  1224.551334  \n2       5011656    95  13:07:00  02:43:00   1.34   908.878736  \n3       5011581    95  13:07:00  02:43:00   1.50   161.204428  \n4       5011567    95  13:07:00  02:43:00   1.34   241.258531  \n...         ...   ...       ...       ...    ...          ...  \n287131  5008634    96  12:56:00  03:04:00   1.60   892.331554  \n287132  5008518    96  12:56:00  03:04:00   1.39   283.975120  \n287133  5008543    96  12:56:00  03:04:00   1.43    89.767305  \n287134  5008600    96  12:56:00  03:04:00   1.53   423.187635  \n287135  5008820    96  12:56:00  03:04:00   1.66   814.243109  \n\n[287136 rows x 18 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>traj_id</th>\n      <th>DateTime</th>\n      <th>lat</th>\n      <th>lon</th>\n      <th>StarkeyTime</th>\n      <th>GMDate</th>\n      <th>GMTime</th>\n      <th>LocDate</th>\n      <th>LocTime</th>\n      <th>RadNum</th>\n      <th>Species</th>\n      <th>UTME</th>\n      <th>UTMN</th>\n      <th>Year</th>\n      <th>Grensunr</th>\n      <th>Grensuns</th>\n      <th>Obswt</th>\n      <th>Distance</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>880109D01</td>\n      <td>1995-04-13 13:40:06</td>\n      <td>45.239682</td>\n      <td>-118.533204</td>\n      <td>229902006</td>\n      <td>21:40:06</td>\n      <td>19950413</td>\n      <td>19950413</td>\n      <td>13:40:06</td>\n      <td>409</td>\n      <td>0</td>\n      <td>379662</td>\n      <td>5010734</td>\n      <td>95</td>\n      <td>13:13:00</td>\n      <td>02:39:00</td>\n      <td>1.47</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>880109D01</td>\n      <td>1995-04-15 12:16:15</td>\n      <td>45.250521</td>\n      <td>-118.530438</td>\n      <td>230069775</td>\n      <td>20:16:15</td>\n      <td>19950415</td>\n      <td>19950415</td>\n      <td>12:16:15</td>\n      <td>409</td>\n      <td>0</td>\n      <td>379895</td>\n      <td>5011927</td>\n      <td>95</td>\n      <td>13:09:00</td>\n      <td>02:41:00</td>\n      <td>1.59</td>\n      <td>1224.551334</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>880109D01</td>\n      <td>1995-04-15 21:39:38</td>\n      <td>45.247943</td>\n      <td>-118.541455</td>\n      <td>230103578</td>\n      <td>05:39:38</td>\n      <td>19950416</td>\n      <td>19950415</td>\n      <td>21:39:38</td>\n      <td>409</td>\n      <td>0</td>\n      <td>379039</td>\n      <td>5011656</td>\n      <td>95</td>\n      <td>13:07:00</td>\n      <td>02:43:00</td>\n      <td>1.34</td>\n      <td>908.878736</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>880109D01</td>\n      <td>1995-04-16 03:32:14</td>\n      <td>45.247429</td>\n      <td>-118.539530</td>\n      <td>230124734</td>\n      <td>11:32:14</td>\n      <td>19950416</td>\n      <td>19950416</td>\n      <td>03:32:14</td>\n      <td>409</td>\n      <td>0</td>\n      <td>379188</td>\n      <td>5011581</td>\n      <td>95</td>\n      <td>13:07:00</td>\n      <td>02:43:00</td>\n      <td>1.50</td>\n      <td>161.204428</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>880109D01</td>\n      <td>1995-04-16 04:08:28</td>\n      <td>45.247117</td>\n      <td>-118.542579</td>\n      <td>230126908</td>\n      <td>12:08:28</td>\n      <td>19950416</td>\n      <td>19950416</td>\n      <td>04:08:28</td>\n      <td>409</td>\n      <td>0</td>\n      <td>378938</td>\n      <td>5011567</td>\n      <td>95</td>\n      <td>13:07:00</td>\n      <td>02:43:00</td>\n      <td>1.34</td>\n      <td>241.258531</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>287131</th>\n      <td>OSUX93191</td>\n      <td>1996-08-15 06:51:06</td>\n      <td>45.220642</td>\n      <td>-118.543392</td>\n      <td>272213466</td>\n      <td>14:51:06</td>\n      <td>19960815</td>\n      <td>19960815</td>\n      <td>06:51:06</td>\n      <td>390</td>\n      <td>2</td>\n      <td>378821</td>\n      <td>5008634</td>\n      <td>96</td>\n      <td>12:56:00</td>\n      <td>03:04:00</td>\n      <td>1.60</td>\n      <td>892.331554</td>\n    </tr>\n    <tr>\n      <th>287132</th>\n      <td>OSUX93191</td>\n      <td>1996-08-15 08:45:15</td>\n      <td>45.219785</td>\n      <td>-118.546807</td>\n      <td>272220315</td>\n      <td>16:45:15</td>\n      <td>19960815</td>\n      <td>19960815</td>\n      <td>08:45:15</td>\n      <td>390</td>\n      <td>2</td>\n      <td>378568</td>\n      <td>5008518</td>\n      <td>96</td>\n      <td>12:56:00</td>\n      <td>03:04:00</td>\n      <td>1.39</td>\n      <td>283.975120</td>\n    </tr>\n    <tr>\n      <th>287133</th>\n      <td>OSUX93191</td>\n      <td>1996-08-15 10:36:54</td>\n      <td>45.219801</td>\n      <td>-118.545661</td>\n      <td>272227014</td>\n      <td>18:36:54</td>\n      <td>19960815</td>\n      <td>19960815</td>\n      <td>10:36:54</td>\n      <td>390</td>\n      <td>2</td>\n      <td>378645</td>\n      <td>5008543</td>\n      <td>96</td>\n      <td>12:56:00</td>\n      <td>03:04:00</td>\n      <td>1.43</td>\n      <td>89.767305</td>\n    </tr>\n    <tr>\n      <th>287134</th>\n      <td>OSUX93191</td>\n      <td>1996-08-15 12:31:22</td>\n      <td>45.220268</td>\n      <td>-118.551024</td>\n      <td>272233882</td>\n      <td>20:31:22</td>\n      <td>19960815</td>\n      <td>19960815</td>\n      <td>12:31:22</td>\n      <td>390</td>\n      <td>2</td>\n      <td>378232</td>\n      <td>5008600</td>\n      <td>96</td>\n      <td>12:56:00</td>\n      <td>03:04:00</td>\n      <td>1.53</td>\n      <td>423.187635</td>\n    </tr>\n    <tr>\n      <th>287135</th>\n      <td>OSUX93191</td>\n      <td>1996-08-15 14:25:58</td>\n      <td>45.222562</td>\n      <td>-118.541151</td>\n      <td>272240758</td>\n      <td>22:25:58</td>\n      <td>19960815</td>\n      <td>19960815</td>\n      <td>14:25:58</td>\n      <td>390</td>\n      <td>2</td>\n      <td>378995</td>\n      <td>5008820</td>\n      <td>96</td>\n      <td>12:56:00</td>\n      <td>03:04:00</td>\n      <td>1.66</td>\n      <td>814.243109</td>\n    </tr>\n  </tbody>\n</table>\n<p>287136 rows Ã— 18 columns</p>\n</div>"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = PTRAILDataFrame(pd.read_csv('./starkey.csv'), traj_id='traj_id',\n",
    "                          datetime='DateTime', latitude='lat', longitude='lon')\n",
    "ready_dataset = KinematicFeatures.create_distance_column(dataset)\n",
    "\n",
    "ready_dataset.reset_index(inplace=True)\n",
    "ready_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "46da1e90",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\\ |                        #                          | 2 Elapsed Time: 0:02:15"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['14159, random, on, 0.33, 0.9578571428571427', '14159, fewest, on, 0.33, 0.9374600414878596', '14159, proportional, on, 0.33, 0.8120335621662852']\n",
      "CPU times: user 3min 17s, sys: 7.39 s, total: 3min 25s\n",
      "Wall time: 3min 36s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# seed_vals = [14159, 26535, 89793]\n",
    "# selection_vals = ['random', 'class', 'proportional']\n",
    "# augment_vals = ['on', 'in']\n",
    "\n",
    "seed_vals = [14159]\n",
    "selection_vals = ['random', 'fewest', 'proportional']\n",
    "augment_vals = ['on']\n",
    "augment_percents = [0.33]\n",
    "\n",
    "i = 0\n",
    "lst = []\n",
    "bar = progressbar.ProgressBar(max_value=progressbar.UnknownLength)\n",
    "for s in seed_vals:\n",
    "    for sel in selection_vals:\n",
    "        for aug in augment_vals:\n",
    "            for percent in augment_percents:\n",
    "                bar.update(i)\n",
    "                i += 1\n",
    "                # Create the model.\n",
    "                model = RandomForestClassifier(random_state=s)\n",
    "\n",
    "                # Get the augmented data.\n",
    "                data = augment_and_create_train_test_splits(ready_dataset, s, 'Species', sel, aug, percent)\n",
    "\n",
    "                # Fit the model and perform testing.\n",
    "                model.fit(data[0], data[1])\n",
    "                test_predict = model.predict(data[2])\n",
    "                performance_val = f1_score(data[3], test_predict, average='weighted')\n",
    "                # Add the value to dict.\n",
    "                lst.append(f\"{s}, {sel}, {aug}, {percent}, {performance_val}\")\n",
    "\n",
    "print(lst)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
