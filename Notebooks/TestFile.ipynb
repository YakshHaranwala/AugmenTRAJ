{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bba5a4d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import sys\n",
    "# sys.path.append('/home/nicholasjesperson/Documents/School/Comp4780/Data_Augmentation/Data Augmentation/paper/AugmenTRAJ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "686bdbad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.augmentation.augment import Augmentation\n",
    "from src.selection.select import Selection\n",
    "from src.utils.alter import Alter\n",
    "import math\n",
    "import pandas as pd\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import f1_score\n",
    "from random import *\n",
    "from ptrail.core.TrajectoryDF import PTRAILDataFrame\n",
    "from ptrail.preprocessing.filters import Filters\n",
    "from ptrail.core.Datasets import Datasets\n",
    "from ptrail.preprocessing.statistics import Statistics\n",
    "from ptrail.features.kinematic_features import KinematicFeatures\n",
    "\n",
    "# pd.set_option('use_inf_as_na', True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "867f222b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def trajectoryAugumentationProcedure(trajs, seed, n, k, pradius, model):\n",
    "    myRandom = Random(seed * (n * k * pradius))\n",
    "\n",
    "    #Split data must be changed\n",
    "    splits = Selection.select_randomly(trajs, .2)\n",
    "    # splits = Selection.select_traj_with_fewest(trajs, myRandom, .2)\n",
    "    # splits = Selection.select_representative_trajectories(trajs, 'VesselType')\n",
    "\n",
    "    paramTestingDataSet = Filters.remove_duplicates(dataframe=trajs)\n",
    "\n",
    "    trainDataParm = paramTestingDataSet.loc[paramTestingDataSet.traj_id.isin(splits[\"train\"]) == True].dropna()\n",
    "    testDataParm = paramTestingDataSet.loc[paramTestingDataSet.traj_id.isin(splits[\"test\"]) == True].dropna()\n",
    "    testData = PTRAILDataFrame(data_set=testDataParm,\n",
    "                               latitude='lat',\n",
    "                               longitude='lon',\n",
    "                               datetime='DateTime',\n",
    "                               traj_id='traj_id')\n",
    "    statsTestParm = Statistics.generate_kinematic_stats(dataframe=testData,\n",
    "                                                target_col_name='Status')\n",
    "    pivotedStatsTestParm = Statistics.pivot_stats_df(dataframe=statsTestParm,\n",
    "                                              target_col_name='Status')\n",
    "    pivotedStatsTestParm = pivotedStatsTestParm.loc[:,~pivotedStatsTestParm.columns.duplicated()]\n",
    "    testParmX = pivotedStatsTestParm.drop(columns='Status')\n",
    "    testParmY = pivotedStatsTestParm['Status'].to_numpy()\n",
    "    noiseTraj = trainDataParm['traj_id'].unique()\n",
    "\n",
    "    sampledTraj = myRandom.choices(sorted(noiseTraj), k=math.floor(n * len(noiseTraj)))\n",
    "    for traj in sampledTraj:\n",
    "        trajToChange = trainDataParm.loc[trainDataParm.traj_id == traj]\n",
    "    \n",
    "    \n",
    "    \n",
    "        #Trajectory must be changed\n",
    "        # trajChanged = Augmentation.augment_trajectories_with_randomly_generated_points(trajToChange, pradius,\n",
    "        #                                                                              k, 100, myRandom, 'on')\n",
    "        # trajChanged = Augmentation.augment_trajectories_with_randomly_generated_points(trajToChange, pradius,\n",
    "        #                                                                               k, 100, myRandom, 'in')\n",
    "        trajChanged = Augmentation.augment_trajectories_with_interpolation(trajToChange, 3600*4, 'cubic')\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        trainDataParm = pd.concat([trainDataParm, trajChanged], ignore_index = True)\n",
    "\n",
    "    #trainDataNoiseFilt = trainDataParm.filter([\"traj_id\", \"DateTime\",\"vehicle_type\", \"velocity\" ,\"VesselType\" \"lon\", \"lat\", \"kilopost\",\"vehicle_length\", \"detected_flag\"])\n",
    "\n",
    "\n",
    "\n",
    "    trainDataNoise = PTRAILDataFrame(data_set=trainDataParm,\n",
    "                                            datetime='DateTime',\n",
    "                                            traj_id='traj_id',\n",
    "                                            latitude='lat',\n",
    "                                            longitude='lon')\n",
    "    \n",
    "    statsTrainNoiseParm = Statistics.generate_kinematic_stats(dataframe=trainDataNoise,\n",
    "                                                        target_col_name='Status')\n",
    "\n",
    "    pivotedStatsTrainNoiseParm = Statistics.pivot_stats_df(dataframe=statsTrainNoiseParm,\n",
    "                                                      target_col_name='Status')\n",
    "\n",
    "    pivotedStatsTrainNoise = pivotedStatsTrainNoiseParm.loc[:,~pivotedStatsTrainNoiseParm.columns.duplicated()]\n",
    "\n",
    "    \n",
    "    pivotedStatsTrainNoise=pivotedStatsTrainNoise.dropna()\n",
    "    \n",
    "    trainParmX = pivotedStatsTrainNoise.drop(columns='Status')\n",
    "    trainParmY = pivotedStatsTrainNoise['Status'].to_numpy()\n",
    "\n",
    "    testParmX = testParmX.interpolate()\n",
    "\n",
    "    model.fit(trainParmX, trainParmY)\n",
    "    test_predict = model.predict(testParmX)\n",
    "    performance_val = f1_score(testParmY, test_predict, average='weighted')\n",
    "    print(f\"Current run: k={k}, pradius={pradius}, n={n}, fscore={performance_val}, seed={seed}\")\n",
    "    return str(f\"{n},{k},{pradius},{performance_val}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "223daf66",
   "metadata": {
    "scrolled": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------ Dataset Facts ------------------------------\n",
      "\n",
      "Number of unique Trajectories in the data: 1814\n",
      "Number of points in the data: 49105\n",
      "Dataset time range: 60041 days 12:00:00\n",
      "Datatype of the DataFrame: <class 'ptrail.core.TrajectoryDF.PTRAILDataFrame'>\n",
      "Dataset Bounding Box: (7.2, -109.5, 81.0, 63.0)\n",
      "\n",
      "---------------------------------------------------------------------\n",
      "Current run: k=0.1, pradius=0.001, n=0.2, fscore=0.5728002786915206, seed=14159\n",
      "Current run: k=0.1, pradius=0.001, n=0.2, fscore=0.509933413346582, seed=26535\n",
      "Current run: k=0.1, pradius=0.001, n=0.2, fscore=0.49702339393488426, seed=89793\n",
      "Current run: k=0.1, pradius=0.005, n=0.2, fscore=0.519308877654176, seed=14159\n",
      "Current run: k=0.1, pradius=0.005, n=0.2, fscore=0.5619644284956808, seed=26535\n",
      "Current run: k=0.1, pradius=0.005, n=0.2, fscore=0.5606786504946463, seed=89793\n",
      "Current run: k=0.1, pradius=0.01, n=0.2, fscore=0.5302585980786674, seed=14159\n",
      "Current run: k=0.1, pradius=0.01, n=0.2, fscore=0.5343058687370248, seed=26535\n",
      "Current run: k=0.1, pradius=0.01, n=0.2, fscore=0.5780016792157486, seed=89793\n",
      "Current run: k=0.2, pradius=0.001, n=0.2, fscore=0.5351532320370848, seed=14159\n",
      "Current run: k=0.2, pradius=0.001, n=0.2, fscore=0.5531468926553673, seed=26535\n",
      "Current run: k=0.2, pradius=0.001, n=0.2, fscore=0.5304705748190485, seed=89793\n",
      "Current run: k=0.2, pradius=0.005, n=0.2, fscore=0.5224043335309727, seed=14159\n",
      "Current run: k=0.2, pradius=0.005, n=0.2, fscore=0.5238836077730108, seed=26535\n",
      "Current run: k=0.2, pradius=0.005, n=0.2, fscore=0.5436232532940682, seed=89793\n",
      "Current run: k=0.2, pradius=0.01, n=0.2, fscore=0.5611172689934869, seed=14159\n",
      "Current run: k=0.2, pradius=0.01, n=0.2, fscore=0.5361653766892215, seed=26535\n",
      "Current run: k=0.2, pradius=0.01, n=0.2, fscore=0.5064230699939681, seed=89793\n",
      "Current run: k=0.3, pradius=0.001, n=0.2, fscore=0.51085063669181, seed=14159\n",
      "Current run: k=0.3, pradius=0.001, n=0.2, fscore=0.48572953305890637, seed=26535\n",
      "Current run: k=0.3, pradius=0.001, n=0.2, fscore=0.5436954327343535, seed=89793\n",
      "Current run: k=0.3, pradius=0.005, n=0.2, fscore=0.5888187919437919, seed=14159\n",
      "Current run: k=0.3, pradius=0.005, n=0.2, fscore=0.49527241605427064, seed=26535\n",
      "Current run: k=0.3, pradius=0.005, n=0.2, fscore=0.4937682016759177, seed=89793\n",
      "Current run: k=0.3, pradius=0.01, n=0.2, fscore=0.5111547188707886, seed=14159\n",
      "Current run: k=0.3, pradius=0.01, n=0.2, fscore=0.5460852960146068, seed=26535\n",
      "Current run: k=0.3, pradius=0.01, n=0.2, fscore=0.5350287500223563, seed=89793\n",
      "Current run: k=0.1, pradius=0.001, n=0.3, fscore=0.4928149732006238, seed=14159\n",
      "Current run: k=0.1, pradius=0.001, n=0.3, fscore=0.49839204282154775, seed=26535\n",
      "Current run: k=0.1, pradius=0.001, n=0.3, fscore=0.5384935497295048, seed=89793\n",
      "Current run: k=0.1, pradius=0.005, n=0.3, fscore=0.554003239850157, seed=14159\n",
      "Current run: k=0.1, pradius=0.005, n=0.3, fscore=0.5587711896430688, seed=26535\n",
      "Current run: k=0.1, pradius=0.005, n=0.3, fscore=0.5378765260773193, seed=89793\n",
      "Current run: k=0.1, pradius=0.01, n=0.3, fscore=0.4991130001933286, seed=14159\n",
      "Current run: k=0.1, pradius=0.01, n=0.3, fscore=0.566292903592828, seed=26535\n",
      "Current run: k=0.1, pradius=0.01, n=0.3, fscore=0.5317601691265708, seed=89793\n",
      "Current run: k=0.2, pradius=0.001, n=0.3, fscore=0.5260822111271287, seed=14159\n",
      "Current run: k=0.2, pradius=0.001, n=0.3, fscore=0.5439912275386418, seed=26535\n",
      "Current run: k=0.2, pradius=0.001, n=0.3, fscore=0.5383197527145162, seed=89793\n",
      "Current run: k=0.2, pradius=0.005, n=0.3, fscore=0.5006200633985718, seed=14159\n",
      "Current run: k=0.2, pradius=0.005, n=0.3, fscore=0.5415038618809631, seed=26535\n",
      "Current run: k=0.2, pradius=0.005, n=0.3, fscore=0.5132192719526026, seed=89793\n",
      "Current run: k=0.2, pradius=0.01, n=0.3, fscore=0.446964016127027, seed=14159\n",
      "Current run: k=0.2, pradius=0.01, n=0.3, fscore=0.5505501099221526, seed=26535\n",
      "Current run: k=0.2, pradius=0.01, n=0.3, fscore=0.5283112411990223, seed=89793\n",
      "Current run: k=0.3, pradius=0.001, n=0.3, fscore=0.5465999038974241, seed=14159\n",
      "Current run: k=0.3, pradius=0.001, n=0.3, fscore=0.5032731247400004, seed=26535\n",
      "Current run: k=0.3, pradius=0.001, n=0.3, fscore=0.5220464305059633, seed=89793\n",
      "Current run: k=0.3, pradius=0.005, n=0.3, fscore=0.5515454046678329, seed=14159\n",
      "Current run: k=0.3, pradius=0.005, n=0.3, fscore=0.5269486188308667, seed=26535\n",
      "Current run: k=0.3, pradius=0.005, n=0.3, fscore=0.5095817361621529, seed=89793\n",
      "Current run: k=0.3, pradius=0.01, n=0.3, fscore=0.5327876750638232, seed=14159\n",
      "Current run: k=0.3, pradius=0.01, n=0.3, fscore=0.5500313873195228, seed=26535\n",
      "Current run: k=0.3, pradius=0.01, n=0.3, fscore=0.4830928454717331, seed=89793\n",
      "Current run: k=0.1, pradius=0.001, n=0.4, fscore=0.5397530908645464, seed=14159\n",
      "Current run: k=0.1, pradius=0.001, n=0.4, fscore=0.5423265125664466, seed=26535\n",
      "Current run: k=0.1, pradius=0.001, n=0.4, fscore=0.5528838122088614, seed=89793\n",
      "Current run: k=0.1, pradius=0.005, n=0.4, fscore=0.46305711516799136, seed=14159\n",
      "Current run: k=0.1, pradius=0.005, n=0.4, fscore=0.5462542854930241, seed=26535\n",
      "Current run: k=0.1, pradius=0.005, n=0.4, fscore=0.5782698297790312, seed=89793\n",
      "Current run: k=0.1, pradius=0.01, n=0.4, fscore=0.550537511307557, seed=14159\n",
      "Current run: k=0.1, pradius=0.01, n=0.4, fscore=0.5104853429665483, seed=26535\n",
      "Current run: k=0.1, pradius=0.01, n=0.4, fscore=0.5622778133769829, seed=89793\n",
      "Current run: k=0.2, pradius=0.001, n=0.4, fscore=0.5512346663057264, seed=14159\n",
      "Current run: k=0.2, pradius=0.001, n=0.4, fscore=0.5303280424705565, seed=26535\n",
      "Current run: k=0.2, pradius=0.001, n=0.4, fscore=0.5179555905699756, seed=89793\n",
      "Current run: k=0.2, pradius=0.005, n=0.4, fscore=0.5039954435915488, seed=14159\n",
      "Current run: k=0.2, pradius=0.005, n=0.4, fscore=0.5383307390834607, seed=26535\n",
      "Current run: k=0.2, pradius=0.005, n=0.4, fscore=0.5232424638382687, seed=89793\n",
      "Current run: k=0.2, pradius=0.01, n=0.4, fscore=0.5713359774605485, seed=14159\n",
      "Current run: k=0.2, pradius=0.01, n=0.4, fscore=0.5139918894804375, seed=26535\n",
      "Current run: k=0.2, pradius=0.01, n=0.4, fscore=0.5661026832934365, seed=89793\n",
      "Current run: k=0.3, pradius=0.001, n=0.4, fscore=0.5101432706478035, seed=14159\n",
      "Current run: k=0.3, pradius=0.001, n=0.4, fscore=0.518373537070421, seed=26535\n",
      "Current run: k=0.3, pradius=0.001, n=0.4, fscore=0.5108283076648227, seed=89793\n",
      "Current run: k=0.3, pradius=0.005, n=0.4, fscore=0.5352585443965001, seed=14159\n",
      "Current run: k=0.3, pradius=0.005, n=0.4, fscore=0.5276269893094552, seed=26535\n",
      "Current run: k=0.3, pradius=0.005, n=0.4, fscore=0.5941761803423713, seed=89793\n",
      "Current run: k=0.3, pradius=0.01, n=0.4, fscore=0.4987794713026911, seed=14159\n",
      "Current run: k=0.3, pradius=0.01, n=0.4, fscore=0.5217043289992405, seed=26535\n",
      "Current run: k=0.3, pradius=0.01, n=0.4, fscore=0.5270264008292177, seed=89793\n",
      "CPU times: user 2h 30min 44s, sys: 26min 27s, total: 2h 57min 12s\n",
      "Wall time: 5h 45min 16s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "dataset = Datasets.load_hurricanes()\n",
    "ready_dataset = Filters.remove_duplicates(dataframe=dataset)\n",
    "\n",
    "seeds = [14159,26535,89793]\n",
    "n_vals = [.2, .3, .4]\n",
    "k_vals = [.1, .2, .3]\n",
    "rad_vals = [.001, .005, .01]\n",
    "\n",
    "\n",
    "#Rename results file to name of tests run\n",
    "text_file = open(\"./Hurricane Results/HurricanesRandomSampleInterpolation.txt\", \"w\")\n",
    "for n in n_vals:\n",
    "    for k in k_vals:\n",
    "        for rad in rad_vals:\n",
    "            for s in seeds:\n",
    "                result = (trajectoryAugumentationProcedure(ready_dataset, s, n, k,\n",
    "                                                       rad, RandomForestClassifier(random_state=s)))\n",
    "                # print(result)\n",
    "                text_file.writelines(result)\n",
    "text_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './Ships Results/HurricaneRandomSampleInterpolation.txt'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mFileNotFoundError\u001B[0m                         Traceback (most recent call last)",
      "\u001B[0;32m/tmp/ipykernel_18140/2051122794.py\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[0;32m----> 1\u001B[0;31m \u001B[0mpd\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mread_csv\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m'./Ships Results/HurricaneRandomSampleInterpolation.txt'\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mheader\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;32mNone\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdescribe\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[0;32m~/anaconda3/envs/PreprocessingLibrary/lib/python3.8/site-packages/pandas/io/parsers.py\u001B[0m in \u001B[0;36mread_csv\u001B[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001B[0m\n\u001B[1;32m    608\u001B[0m     \u001B[0mkwds\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mupdate\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mkwds_defaults\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    609\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 610\u001B[0;31m     \u001B[0;32mreturn\u001B[0m \u001B[0m_read\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mfilepath_or_buffer\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mkwds\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    611\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    612\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/envs/PreprocessingLibrary/lib/python3.8/site-packages/pandas/io/parsers.py\u001B[0m in \u001B[0;36m_read\u001B[0;34m(filepath_or_buffer, kwds)\u001B[0m\n\u001B[1;32m    460\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    461\u001B[0m     \u001B[0;31m# Create the parser.\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 462\u001B[0;31m     \u001B[0mparser\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mTextFileReader\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mfilepath_or_buffer\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwds\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    463\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    464\u001B[0m     \u001B[0;32mif\u001B[0m \u001B[0mchunksize\u001B[0m \u001B[0;32mor\u001B[0m \u001B[0miterator\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/envs/PreprocessingLibrary/lib/python3.8/site-packages/pandas/io/parsers.py\u001B[0m in \u001B[0;36m__init__\u001B[0;34m(self, f, engine, **kwds)\u001B[0m\n\u001B[1;32m    817\u001B[0m             \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0moptions\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m\"has_index_names\"\u001B[0m\u001B[0;34m]\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mkwds\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m\"has_index_names\"\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    818\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 819\u001B[0;31m         \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_engine\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_make_engine\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mengine\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    820\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    821\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0mclose\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/envs/PreprocessingLibrary/lib/python3.8/site-packages/pandas/io/parsers.py\u001B[0m in \u001B[0;36m_make_engine\u001B[0;34m(self, engine)\u001B[0m\n\u001B[1;32m   1048\u001B[0m             )\n\u001B[1;32m   1049\u001B[0m         \u001B[0;31m# error: Too many arguments for \"ParserBase\"\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1050\u001B[0;31m         \u001B[0;32mreturn\u001B[0m \u001B[0mmapping\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mengine\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mf\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0moptions\u001B[0m\u001B[0;34m)\u001B[0m  \u001B[0;31m# type: ignore[call-arg]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1051\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1052\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0m_failover_to_python\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/envs/PreprocessingLibrary/lib/python3.8/site-packages/pandas/io/parsers.py\u001B[0m in \u001B[0;36m__init__\u001B[0;34m(self, src, **kwds)\u001B[0m\n\u001B[1;32m   1865\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1866\u001B[0m         \u001B[0;31m# open handles\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1867\u001B[0;31m         \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_open_handles\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0msrc\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mkwds\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1868\u001B[0m         \u001B[0;32massert\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mhandles\u001B[0m \u001B[0;32mis\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1869\u001B[0m         \u001B[0;32mfor\u001B[0m \u001B[0mkey\u001B[0m \u001B[0;32min\u001B[0m \u001B[0;34m(\u001B[0m\u001B[0;34m\"storage_options\"\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m\"encoding\"\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m\"memory_map\"\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m\"compression\"\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/envs/PreprocessingLibrary/lib/python3.8/site-packages/pandas/io/parsers.py\u001B[0m in \u001B[0;36m_open_handles\u001B[0;34m(self, src, kwds)\u001B[0m\n\u001B[1;32m   1360\u001B[0m         \u001B[0mLet\u001B[0m \u001B[0mthe\u001B[0m \u001B[0mreaders\u001B[0m \u001B[0mopen\u001B[0m \u001B[0mIOHanldes\u001B[0m \u001B[0mafter\u001B[0m \u001B[0mthey\u001B[0m \u001B[0mare\u001B[0m \u001B[0mdone\u001B[0m \u001B[0;32mwith\u001B[0m \u001B[0mtheir\u001B[0m \u001B[0mpotential\u001B[0m \u001B[0mraises\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1361\u001B[0m         \"\"\"\n\u001B[0;32m-> 1362\u001B[0;31m         self.handles = get_handle(\n\u001B[0m\u001B[1;32m   1363\u001B[0m             \u001B[0msrc\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1364\u001B[0m             \u001B[0;34m\"r\"\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/envs/PreprocessingLibrary/lib/python3.8/site-packages/pandas/io/common.py\u001B[0m in \u001B[0;36mget_handle\u001B[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001B[0m\n\u001B[1;32m    645\u001B[0m                 \u001B[0merrors\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m\"replace\"\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    646\u001B[0m             \u001B[0;31m# Encoding\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 647\u001B[0;31m             handle = open(\n\u001B[0m\u001B[1;32m    648\u001B[0m                 \u001B[0mhandle\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    649\u001B[0m                 \u001B[0mioargs\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mmode\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mFileNotFoundError\u001B[0m: [Errno 2] No such file or directory: './Ships Results/HurricaneRandomSampleInterpolation.txt'"
     ]
    }
   ],
   "source": [
    "pd.read_csv('./Ships Results/RandomSampleInterpolation.txt', header=None).describe()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}